{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:37:21.585821Z",
     "iopub.status.busy": "2025-11-10T07:37:21.585056Z",
     "iopub.status.idle": "2025-11-10T07:39:13.494204Z",
     "shell.execute_reply": "2025-11-10T07:39:13.493537Z",
     "shell.execute_reply.started": "2025-11-10T07:37:21.585792Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Class  Image_Count\n",
      "0      achulu/aa          945\n",
      "1    hallulu/ana          674\n",
      "2     hallulu/ch          671\n",
      "3      hallulu/r          670\n",
      "4   hallulu/thah          669\n",
      "5    hallulu/dha          659\n",
      "6     hallulu/dh          655\n",
      "7     hallulu/th          646\n",
      "8    hallulu/cha          640\n",
      "9    hallulu/tha          617\n",
      "10   hallulu/jha          604\n",
      "11    hallulu/da          603\n",
      "12    hallulu/bh          602\n",
      "13     achulu/uu          599\n",
      "14    hallulu/sa          596\n",
      "15      achulu/u          594\n",
      "16     achulu/ii          594\n",
      "17    hallulu/gh          592\n",
      "18     hallulu/b          591\n",
      "19      achulu/e          588\n",
      "20    hallulu/rr          582\n",
      "21     achulu/am          581\n",
      "22     hallulu/m          579\n",
      "23    hallulu/ll          579\n",
      "24      achulu/a          579\n",
      "25     hallulu/l          578\n",
      "26     achulu/ru          578\n",
      "27     hallulu/P          577\n",
      "28     hallulu/n          574\n",
      "29      achulu/o          574\n",
      "30     achulu/oo          573\n",
      "31     achulu/ao          573\n",
      "32     hallulu/h          569\n",
      "33     achulu/ee          567\n",
      "34     hallulu/v          565\n",
      "35    hallulu/ks          561\n",
      "36    hallulu/jh          560\n",
      "37     achulu/ai          553\n",
      "38     achulu/ah          553\n",
      "39      achulu/i          552\n",
      "40     hallulu/y          550\n",
      "41     hallulu/d          543\n",
      "42    hallulu/sh          543\n",
      "43    achulu/ruu          543\n",
      "44     hallulu/s          542\n",
      "45    hallulu/ta          533\n",
      "46    hallulu/Ph          530\n",
      "47   hallulu/kha          433\n",
      "48     hallulu/g          342\n",
      "49    hallulu/ka          318\n",
      "50   hallulu/jna           51\n",
      "\n",
      "âœ… Saved class counts to telugu_class_counts.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = \"/kaggle/input/finalhope/FINALDATASET\"\n",
    "\n",
    "def count_images(base_path):\n",
    "    letter_counts = {}\n",
    "    for category in os.listdir(base_path):  \n",
    "        category_path = os.path.join(base_path, category)\n",
    "        if not os.path.isdir(category_path):\n",
    "            continue\n",
    "        for letter in os.listdir(category_path):  \n",
    "            letter_path = os.path.join(category_path, letter)\n",
    "            if os.path.isdir(letter_path):\n",
    "                image_count = sum(\n",
    "                    len(files) for _, _, files in os.walk(letter_path)\n",
    "                    if any(f.lower().endswith(('.png', '.jpg', '.jpeg')) for f in files)\n",
    "                )\n",
    "                letter_counts[f\"{category}/{letter}\"] = image_count\n",
    "    return letter_counts\n",
    "\n",
    "\n",
    "counts = count_images(dataset_path)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list(counts.items()), columns=[\"Class\", \"Image_Count\"])\n",
    "df = df.sort_values(by=\"Image_Count\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "df.to_csv(\"telugu_class_counts.csv\", index=False)\n",
    "print(\"\\nâœ… Saved class counts to telugu_class_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:39:13.495886Z",
     "iopub.status.busy": "2025-11-10T07:39:13.495646Z",
     "iopub.status.idle": "2025-11-10T07:42:53.264387Z",
     "shell.execute_reply": "2025-11-10T07:42:53.263656Z",
     "shell.execute_reply.started": "2025-11-10T07:39:13.495869Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 07:39:16.633398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762760357.045510      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762760357.168554      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ§© Step 1: Balancing classes to 500 images each...\n",
      "\n",
      "ğŸ§¹ achulu/i: trimmed 552 â†’ 500\n",
      "ğŸ§¹ achulu/e: trimmed 588 â†’ 500\n",
      "ğŸ§¹ achulu/u: trimmed 594 â†’ 500\n",
      "ğŸ§¹ achulu/ii: trimmed 594 â†’ 500\n",
      "ğŸ§¹ achulu/a: trimmed 579 â†’ 500\n",
      "ğŸ§¹ achulu/o: trimmed 574 â†’ 500\n",
      "ğŸ§¹ achulu/uu: trimmed 599 â†’ 500\n",
      "ğŸ§¹ achulu/ruu: trimmed 543 â†’ 500\n",
      "ğŸ§¹ achulu/ai: trimmed 553 â†’ 500\n",
      "ğŸ§¹ achulu/ao: trimmed 573 â†’ 500\n",
      "ğŸ§¹ achulu/ru: trimmed 578 â†’ 500\n",
      "ğŸ§¹ achulu/ah: trimmed 553 â†’ 500\n",
      "ğŸ§¹ achulu/am: trimmed 581 â†’ 500\n",
      "ğŸ§¹ achulu/aa: trimmed 945 â†’ 500\n",
      "ğŸ§¹ achulu/oo: trimmed 573 â†’ 500\n",
      "ğŸ§¹ achulu/ee: trimmed 567 â†’ 500\n",
      "ğŸ§¹ hallulu/n: trimmed 574 â†’ 500\n",
      "ğŸ§¹ hallulu/r: trimmed 670 â†’ 500\n",
      "ğŸ§¹ hallulu/sh: trimmed 543 â†’ 500\n",
      "ğŸ§¹ hallulu/b: trimmed 591 â†’ 500\n",
      "ğŸ§¹ hallulu/h: trimmed 569 â†’ 500\n",
      "âš¡ hallulu/jna: augmenting from 51\n",
      "âœ¨ Augmenting /kaggle/working/balanced_52/hallulu/jna from 51 â†’ 500\n",
      "âœ… /kaggle/working/balanced_52/hallulu/jna: now 500 images\n",
      "ğŸ§¹ hallulu/ta: trimmed 533 â†’ 500\n",
      "ğŸ§¹ hallulu/da: trimmed 603 â†’ 500\n",
      "ğŸ§¹ hallulu/ch: trimmed 671 â†’ 500\n",
      "ğŸ§¹ hallulu/m: trimmed 579 â†’ 500\n",
      "ğŸ§¹ hallulu/thah: trimmed 669 â†’ 500\n",
      "ğŸ§¹ hallulu/dha: trimmed 659 â†’ 500\n",
      "ğŸ§¹ hallulu/y: trimmed 550 â†’ 500\n",
      "âš¡ hallulu/kha: augmenting from 433\n",
      "âœ¨ Augmenting /kaggle/working/balanced_52/hallulu/kha from 433 â†’ 500\n",
      "âœ… /kaggle/working/balanced_52/hallulu/kha: now 500 images\n",
      "ğŸ§¹ hallulu/s: trimmed 542 â†’ 500\n",
      "âš¡ hallulu/g: augmenting from 342\n",
      "âœ¨ Augmenting /kaggle/working/balanced_52/hallulu/g from 342 â†’ 500\n",
      "âœ… /kaggle/working/balanced_52/hallulu/g: now 500 images\n",
      "ğŸ§¹ hallulu/jh: trimmed 560 â†’ 500\n",
      "ğŸ§¹ hallulu/rr: trimmed 582 â†’ 500\n",
      "ğŸ§¹ hallulu/tha: trimmed 617 â†’ 500\n",
      "ğŸ§¹ hallulu/jha: trimmed 604 â†’ 500\n",
      "ğŸ§¹ hallulu/v: trimmed 565 â†’ 500\n",
      "ğŸ§¹ hallulu/th: trimmed 646 â†’ 500\n",
      "ğŸ§¹ hallulu/dh: trimmed 655 â†’ 500\n",
      "ğŸ§¹ hallulu/Ph: trimmed 530 â†’ 500\n",
      "ğŸ§¹ hallulu/ll: trimmed 579 â†’ 500\n",
      "ğŸ§¹ hallulu/P: trimmed 577 â†’ 500\n",
      "ğŸ§¹ hallulu/l: trimmed 578 â†’ 500\n",
      "ğŸ§¹ hallulu/cha: trimmed 640 â†’ 500\n",
      "ğŸ§¹ hallulu/gh: trimmed 592 â†’ 500\n",
      "ğŸ§¹ hallulu/ana: trimmed 674 â†’ 500\n",
      "ğŸ§¹ hallulu/d: trimmed 543 â†’ 500\n",
      "ğŸ§¹ hallulu/bh: trimmed 602 â†’ 500\n",
      "âš¡ hallulu/ka: augmenting from 318\n",
      "âœ¨ Augmenting /kaggle/working/balanced_52/hallulu/ka from 318 â†’ 500\n",
      "âœ… /kaggle/working/balanced_52/hallulu/ka: now 500 images\n",
      "ğŸ§¹ hallulu/ks: trimmed 561 â†’ 500\n",
      "ğŸ§¹ hallulu/sa: trimmed 596 â†’ 500\n",
      "\n",
      "âœ… Step 1 Complete â€” All classes balanced to 500 images.\n",
      "\n",
      "ğŸ§© Step 2: Splitting into train/val/test (70/20/10)...\n",
      "\n",
      "\n",
      "âœ… Step 2 Complete â€” Dataset split created at: /kaggle/working/dataset_70_20_10\n",
      "\n",
      "ğŸ§© Step 3: Verifying counts for each class...\n",
      "\n",
      "Split Category Letter  test  train    val  Total\n",
      "0       achulu      a  50.0  350.0  100.0  500.0\n",
      "1       achulu     aa  50.0  350.0  100.0  500.0\n",
      "2       achulu     ah  50.0  350.0  100.0  500.0\n",
      "3       achulu     ai  50.0  350.0  100.0  500.0\n",
      "4       achulu     am  50.0  350.0  100.0  500.0\n",
      "5       achulu     ao  50.0  350.0  100.0  500.0\n",
      "6       achulu      e  50.0  350.0  100.0  500.0\n",
      "7       achulu     ee  50.0  350.0  100.0  500.0\n",
      "8       achulu      i  50.0  350.0  100.0  500.0\n",
      "9       achulu     ii  50.0  350.0  100.0  500.0\n",
      "10      achulu      o  50.0  350.0  100.0  500.0\n",
      "11      achulu     oo  50.0  350.0  100.0  500.0\n",
      "12      achulu     ru  50.0  350.0  100.0  500.0\n",
      "13      achulu    ruu  50.0  350.0  100.0  500.0\n",
      "14      achulu      u  50.0  350.0  100.0  500.0\n",
      "15      achulu     uu  50.0  350.0  100.0  500.0\n",
      "16     hallulu      P  50.0  350.0  100.0  500.0\n",
      "17     hallulu     Ph  50.0  350.0  100.0  500.0\n",
      "18     hallulu    ana  50.0  350.0  100.0  500.0\n",
      "19     hallulu      b  50.0  350.0  100.0  500.0\n",
      "20     hallulu     bh  50.0  350.0  100.0  500.0\n",
      "21     hallulu     ch  50.0  350.0  100.0  500.0\n",
      "22     hallulu    cha  50.0  350.0  100.0  500.0\n",
      "23     hallulu      d  50.0  350.0  100.0  500.0\n",
      "24     hallulu     da  50.0  350.0  100.0  500.0\n",
      "25     hallulu     dh  50.0  350.0  100.0  500.0\n",
      "26     hallulu    dha  50.0  350.0  100.0  500.0\n",
      "27     hallulu      g  50.0  350.0  100.0  500.0\n",
      "28     hallulu     gh  50.0  350.0  100.0  500.0\n",
      "29     hallulu      h  50.0  350.0  100.0  500.0\n",
      "30     hallulu     jh  50.0  350.0  100.0  500.0\n",
      "31     hallulu    jha  50.0  350.0  100.0  500.0\n",
      "32     hallulu    jna  51.0  345.0   98.0  494.0\n",
      "33     hallulu     ka  51.0  348.0   99.0  498.0\n",
      "34     hallulu    kha  50.0  350.0  100.0  500.0\n",
      "35     hallulu     ks  50.0  350.0  100.0  500.0\n",
      "36     hallulu      l  50.0  350.0  100.0  500.0\n",
      "37     hallulu     ll  50.0  350.0  100.0  500.0\n",
      "38     hallulu      m  50.0  350.0  100.0  500.0\n",
      "39     hallulu      n  50.0  350.0  100.0  500.0\n",
      "40     hallulu      r  50.0  350.0  100.0  500.0\n",
      "41     hallulu     rr  50.0  350.0  100.0  500.0\n",
      "42     hallulu      s  50.0  350.0  100.0  500.0\n",
      "43     hallulu     sa  50.0  350.0  100.0  500.0\n",
      "44     hallulu     sh  50.0  350.0  100.0  500.0\n",
      "45     hallulu     ta  50.0  350.0  100.0  500.0\n",
      "46     hallulu     th  50.0  350.0  100.0  500.0\n",
      "47     hallulu    tha  50.0  350.0  100.0  500.0\n",
      "48     hallulu   thah  50.0  350.0  100.0  500.0\n",
      "49     hallulu      v  50.0  350.0  100.0  500.0\n",
      "50     hallulu      y  50.0  350.0  100.0  500.0\n",
      "\n",
      "ğŸ“Š Summary saved to 'final_dataset_summary.csv'\n",
      "âœ… Minimum total images per class: 494.0\n",
      "âœ… Maximum total images per class: 500.0\n",
      "\n",
      "âš ï¸ Some folders are still off â€” check 'final_dataset_summary.csv'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "\n",
    "src_root = \"/kaggle/input/finalhope/FINALDATASET\"   \n",
    "balanced_root = \"/kaggle/working/balanced_52\"       \n",
    "final_root = \"/kaggle/working/dataset_70_20_10\"     \n",
    "target_per_class = 500                              \n",
    "split_ratios = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}  \n",
    "\n",
    "\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "\n",
    "def augment_images_to_target(folder_path, target_count):\n",
    "    imgs = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not imgs:\n",
    "        print(f\"âš ï¸ Skipping empty folder: {folder_path}\")\n",
    "        return\n",
    "    img_paths = [os.path.join(folder_path, f) for f in imgs]\n",
    "    current_count = len(imgs)\n",
    "    print(f\"âœ¨ Augmenting {folder_path} from {current_count} â†’ {target_count}\")\n",
    "    while current_count < target_count:\n",
    "        img_path = random.choice(img_paths)\n",
    "        img = load_img(img_path)\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        for batch in augmenter.flow(\n",
    "            x, batch_size=1, save_to_dir=folder_path,\n",
    "            save_prefix=\"aug\", save_format=\"png\"\n",
    "        ):\n",
    "            break\n",
    "        current_count += 1\n",
    "    print(f\"âœ… {folder_path}: now {current_count} images\")\n",
    "\n",
    "\n",
    "os.makedirs(balanced_root, exist_ok=True)\n",
    "\n",
    "print(\"\\nğŸ§© Step 1: Balancing classes to 500 images each...\\n\")\n",
    "\n",
    "for category in [\"achulu\", \"hallulu\"]:\n",
    "    cat_path = os.path.join(src_root, category)\n",
    "    dst_cat = os.path.join(balanced_root, category)\n",
    "    os.makedirs(dst_cat, exist_ok=True)\n",
    "\n",
    "    for letter in os.listdir(cat_path):\n",
    "        letter_path = os.path.join(cat_path, letter)\n",
    "        if not os.path.isdir(letter_path):\n",
    "            continue\n",
    "        dst_letter = os.path.join(dst_cat, letter)\n",
    "        os.makedirs(dst_letter, exist_ok=True)\n",
    "\n",
    "        imgs = [f for f in os.listdir(letter_path)\n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        count = len(imgs)\n",
    "\n",
    "        if count > target_per_class:\n",
    "            selected = random.sample(imgs, target_per_class)\n",
    "            for img in selected:\n",
    "                shutil.copy(os.path.join(letter_path, img),\n",
    "                            os.path.join(dst_letter, img))\n",
    "            print(f\"ğŸ§¹ {category}/{letter}: trimmed {count} â†’ {target_per_class}\")\n",
    "\n",
    "        elif count < target_per_class:\n",
    "            for img in imgs:\n",
    "                shutil.copy(os.path.join(letter_path, img),\n",
    "                            os.path.join(dst_letter, img))\n",
    "            print(f\"âš¡ {category}/{letter}: augmenting from {count}\")\n",
    "            augment_images_to_target(dst_letter, target_per_class)\n",
    "        else:\n",
    "            for img in imgs:\n",
    "                shutil.copy(os.path.join(letter_path, img),\n",
    "                            os.path.join(dst_letter, img))\n",
    "            print(f\"âœ… {category}/{letter}: already 500\")\n",
    "\n",
    "print(\"\\nâœ… Step 1 Complete â€” All classes balanced to 500 images.\\n\")\n",
    "\n",
    "print(\"ğŸ§© Step 2: Splitting into train/val/test (70/20/10)...\\n\")\n",
    "\n",
    "for category in [\"achulu\", \"hallulu\"]:\n",
    "    cat_path = os.path.join(balanced_root, category)\n",
    "    for letter in os.listdir(cat_path):\n",
    "        letter_path = os.path.join(cat_path, letter)\n",
    "        imgs = [f for f in os.listdir(letter_path)\n",
    "                if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        random.shuffle(imgs)\n",
    "        n = len(imgs)\n",
    "        n_train = int(n * split_ratios[\"train\"])\n",
    "        n_val = int(n * split_ratios[\"val\"])\n",
    "\n",
    "        splits = {\n",
    "            \"train\": imgs[:n_train],\n",
    "            \"val\": imgs[n_train:n_train+n_val],\n",
    "            \"test\": imgs[n_train+n_val:]\n",
    "        }\n",
    "\n",
    "        for split, files in splits.items():\n",
    "            dst_dir = os.path.join(final_root, split, category, letter)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "            for f in files:\n",
    "                shutil.copy(os.path.join(letter_path, f),\n",
    "                            os.path.join(dst_dir, f))\n",
    "\n",
    "print(\"\\nâœ… Step 2 Complete â€” Dataset split created at:\", final_root)\n",
    "\n",
    "\n",
    "print(\"\\nğŸ§© Step 3: Verifying counts for each class...\\n\")\n",
    "\n",
    "def count_images(base_path):\n",
    "    data = []\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        split_path = os.path.join(base_path, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            continue\n",
    "        for category in [\"achulu\", \"hallulu\"]:\n",
    "            cat_path = os.path.join(split_path, category)\n",
    "            for letter in os.listdir(cat_path):\n",
    "                letter_path = os.path.join(cat_path, letter)\n",
    "                num_imgs = len([\n",
    "                    f for f in os.listdir(letter_path)\n",
    "                    if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "                ])\n",
    "                data.append({\n",
    "                    \"Category\": category,\n",
    "                    \"Letter\": letter,\n",
    "                    \"Split\": split,\n",
    "                    \"Image_Count\": num_imgs\n",
    "                })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = count_images(final_root)\n",
    "summary = df.pivot_table(index=[\"Category\",\"Letter\"], columns=\"Split\",\n",
    "                         values=\"Image_Count\", fill_value=0).reset_index()\n",
    "summary[\"Total\"] = summary[\"train\"] + summary[\"val\"] + summary[\"test\"]\n",
    "\n",
    "print(summary.head(52))\n",
    "summary.to_csv(\"final_dataset_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nğŸ“Š Summary saved to 'final_dataset_summary.csv'\")\n",
    "print(f\"âœ… Minimum total images per class: {summary['Total'].min()}\")\n",
    "print(f\"âœ… Maximum total images per class: {summary['Total'].max()}\")\n",
    "\n",
    "if summary[\"Total\"].min() == summary[\"Total\"].max() == 500:\n",
    "    print(\"\\nğŸ¯ Perfect! Every class has 350 + 100 + 50 = 500 images total.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Some folders are still off â€” check 'final_dataset_summary.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:53.265348Z",
     "iopub.status.busy": "2025-11-10T07:42:53.265132Z",
     "iopub.status.idle": "2025-11-10T07:42:53.278650Z",
     "shell.execute_reply": "2025-11-10T07:42:53.278077Z",
     "shell.execute_reply.started": "2025-11-10T07:42:53.265322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Moved achulu/ee â†’ train/ee\n",
      "ğŸ“‚ Moved achulu/ai â†’ train/ai\n",
      "ğŸ“‚ Moved achulu/ru â†’ train/ru\n",
      "ğŸ“‚ Moved achulu/ao â†’ train/ao\n",
      "ğŸ“‚ Moved achulu/ii â†’ train/ii\n",
      "ğŸ“‚ Moved achulu/u â†’ train/u\n",
      "ğŸ“‚ Moved achulu/ruu â†’ train/ruu\n",
      "ğŸ“‚ Moved achulu/am â†’ train/am\n",
      "ğŸ“‚ Moved achulu/e â†’ train/e\n",
      "ğŸ“‚ Moved achulu/a â†’ train/a\n",
      "ğŸ“‚ Moved achulu/i â†’ train/i\n",
      "ğŸ“‚ Moved achulu/oo â†’ train/oo\n",
      "ğŸ“‚ Moved achulu/aa â†’ train/aa\n",
      "ğŸ“‚ Moved achulu/ah â†’ train/ah\n",
      "ğŸ“‚ Moved achulu/uu â†’ train/uu\n",
      "ğŸ“‚ Moved achulu/o â†’ train/o\n",
      "ğŸ“‚ Moved hallulu/v â†’ train/v\n",
      "ğŸ“‚ Moved hallulu/kha â†’ train/kha\n",
      "ğŸ“‚ Moved hallulu/ll â†’ train/ll\n",
      "ğŸ“‚ Moved hallulu/P â†’ train/P\n",
      "ğŸ“‚ Moved hallulu/dh â†’ train/dh\n",
      "ğŸ“‚ Moved hallulu/cha â†’ train/cha\n",
      "ğŸ“‚ Moved hallulu/jna â†’ train/jna\n",
      "ğŸ“‚ Moved hallulu/d â†’ train/d\n",
      "ğŸ“‚ Moved hallulu/gh â†’ train/gh\n",
      "ğŸ“‚ Moved hallulu/th â†’ train/th\n",
      "ğŸ“‚ Moved hallulu/sa â†’ train/sa\n",
      "ğŸ“‚ Moved hallulu/ch â†’ train/ch\n",
      "ğŸ“‚ Moved hallulu/ana â†’ train/ana\n",
      "ğŸ“‚ Moved hallulu/ks â†’ train/ks\n",
      "ğŸ“‚ Moved hallulu/r â†’ train/r\n",
      "ğŸ“‚ Moved hallulu/ta â†’ train/ta\n",
      "ğŸ“‚ Moved hallulu/da â†’ train/da\n",
      "ğŸ“‚ Moved hallulu/l â†’ train/l\n",
      "ğŸ“‚ Moved hallulu/thah â†’ train/thah\n",
      "ğŸ“‚ Moved hallulu/Ph â†’ train/Ph\n",
      "ğŸ“‚ Moved hallulu/g â†’ train/g\n",
      "ğŸ“‚ Moved hallulu/n â†’ train/n\n",
      "ğŸ“‚ Moved hallulu/tha â†’ train/tha\n",
      "ğŸ“‚ Moved hallulu/s â†’ train/s\n",
      "ğŸ“‚ Moved hallulu/rr â†’ train/rr\n",
      "ğŸ“‚ Moved hallulu/bh â†’ train/bh\n",
      "ğŸ“‚ Moved hallulu/sh â†’ train/sh\n",
      "ğŸ“‚ Moved hallulu/y â†’ train/y\n",
      "ğŸ“‚ Moved hallulu/dha â†’ train/dha\n",
      "ğŸ“‚ Moved hallulu/ka â†’ train/ka\n",
      "ğŸ“‚ Moved hallulu/b â†’ train/b\n",
      "ğŸ“‚ Moved hallulu/jha â†’ train/jha\n",
      "ğŸ“‚ Moved hallulu/h â†’ train/h\n",
      "ğŸ“‚ Moved hallulu/m â†’ train/m\n",
      "ğŸ“‚ Moved hallulu/jh â†’ train/jh\n",
      "ğŸ“‚ Moved achulu/ee â†’ val/ee\n",
      "ğŸ“‚ Moved achulu/ai â†’ val/ai\n",
      "ğŸ“‚ Moved achulu/ru â†’ val/ru\n",
      "ğŸ“‚ Moved achulu/ao â†’ val/ao\n",
      "ğŸ“‚ Moved achulu/ii â†’ val/ii\n",
      "ğŸ“‚ Moved achulu/u â†’ val/u\n",
      "ğŸ“‚ Moved achulu/ruu â†’ val/ruu\n",
      "ğŸ“‚ Moved achulu/am â†’ val/am\n",
      "ğŸ“‚ Moved achulu/e â†’ val/e\n",
      "ğŸ“‚ Moved achulu/a â†’ val/a\n",
      "ğŸ“‚ Moved achulu/i â†’ val/i\n",
      "ğŸ“‚ Moved achulu/oo â†’ val/oo\n",
      "ğŸ“‚ Moved achulu/aa â†’ val/aa\n",
      "ğŸ“‚ Moved achulu/ah â†’ val/ah\n",
      "ğŸ“‚ Moved achulu/uu â†’ val/uu\n",
      "ğŸ“‚ Moved achulu/o â†’ val/o\n",
      "ğŸ“‚ Moved hallulu/v â†’ val/v\n",
      "ğŸ“‚ Moved hallulu/kha â†’ val/kha\n",
      "ğŸ“‚ Moved hallulu/ll â†’ val/ll\n",
      "ğŸ“‚ Moved hallulu/P â†’ val/P\n",
      "ğŸ“‚ Moved hallulu/dh â†’ val/dh\n",
      "ğŸ“‚ Moved hallulu/cha â†’ val/cha\n",
      "ğŸ“‚ Moved hallulu/jna â†’ val/jna\n",
      "ğŸ“‚ Moved hallulu/d â†’ val/d\n",
      "ğŸ“‚ Moved hallulu/gh â†’ val/gh\n",
      "ğŸ“‚ Moved hallulu/th â†’ val/th\n",
      "ğŸ“‚ Moved hallulu/sa â†’ val/sa\n",
      "ğŸ“‚ Moved hallulu/ch â†’ val/ch\n",
      "ğŸ“‚ Moved hallulu/ana â†’ val/ana\n",
      "ğŸ“‚ Moved hallulu/ks â†’ val/ks\n",
      "ğŸ“‚ Moved hallulu/r â†’ val/r\n",
      "ğŸ“‚ Moved hallulu/ta â†’ val/ta\n",
      "ğŸ“‚ Moved hallulu/da â†’ val/da\n",
      "ğŸ“‚ Moved hallulu/l â†’ val/l\n",
      "ğŸ“‚ Moved hallulu/thah â†’ val/thah\n",
      "ğŸ“‚ Moved hallulu/Ph â†’ val/Ph\n",
      "ğŸ“‚ Moved hallulu/g â†’ val/g\n",
      "ğŸ“‚ Moved hallulu/n â†’ val/n\n",
      "ğŸ“‚ Moved hallulu/tha â†’ val/tha\n",
      "ğŸ“‚ Moved hallulu/s â†’ val/s\n",
      "ğŸ“‚ Moved hallulu/rr â†’ val/rr\n",
      "ğŸ“‚ Moved hallulu/bh â†’ val/bh\n",
      "ğŸ“‚ Moved hallulu/sh â†’ val/sh\n",
      "ğŸ“‚ Moved hallulu/y â†’ val/y\n",
      "ğŸ“‚ Moved hallulu/dha â†’ val/dha\n",
      "ğŸ“‚ Moved hallulu/ka â†’ val/ka\n",
      "ğŸ“‚ Moved hallulu/b â†’ val/b\n",
      "ğŸ“‚ Moved hallulu/jha â†’ val/jha\n",
      "ğŸ“‚ Moved hallulu/h â†’ val/h\n",
      "ğŸ“‚ Moved hallulu/m â†’ val/m\n",
      "ğŸ“‚ Moved hallulu/jh â†’ val/jh\n",
      "ğŸ“‚ Moved achulu/ee â†’ test/ee\n",
      "ğŸ“‚ Moved achulu/ai â†’ test/ai\n",
      "ğŸ“‚ Moved achulu/ru â†’ test/ru\n",
      "ğŸ“‚ Moved achulu/ao â†’ test/ao\n",
      "ğŸ“‚ Moved achulu/ii â†’ test/ii\n",
      "ğŸ“‚ Moved achulu/u â†’ test/u\n",
      "ğŸ“‚ Moved achulu/ruu â†’ test/ruu\n",
      "ğŸ“‚ Moved achulu/am â†’ test/am\n",
      "ğŸ“‚ Moved achulu/e â†’ test/e\n",
      "ğŸ“‚ Moved achulu/a â†’ test/a\n",
      "ğŸ“‚ Moved achulu/i â†’ test/i\n",
      "ğŸ“‚ Moved achulu/oo â†’ test/oo\n",
      "ğŸ“‚ Moved achulu/aa â†’ test/aa\n",
      "ğŸ“‚ Moved achulu/ah â†’ test/ah\n",
      "ğŸ“‚ Moved achulu/uu â†’ test/uu\n",
      "ğŸ“‚ Moved achulu/o â†’ test/o\n",
      "ğŸ“‚ Moved hallulu/v â†’ test/v\n",
      "ğŸ“‚ Moved hallulu/kha â†’ test/kha\n",
      "ğŸ“‚ Moved hallulu/ll â†’ test/ll\n",
      "ğŸ“‚ Moved hallulu/P â†’ test/P\n",
      "ğŸ“‚ Moved hallulu/dh â†’ test/dh\n",
      "ğŸ“‚ Moved hallulu/cha â†’ test/cha\n",
      "ğŸ“‚ Moved hallulu/jna â†’ test/jna\n",
      "ğŸ“‚ Moved hallulu/d â†’ test/d\n",
      "ğŸ“‚ Moved hallulu/gh â†’ test/gh\n",
      "ğŸ“‚ Moved hallulu/th â†’ test/th\n",
      "ğŸ“‚ Moved hallulu/sa â†’ test/sa\n",
      "ğŸ“‚ Moved hallulu/ch â†’ test/ch\n",
      "ğŸ“‚ Moved hallulu/ana â†’ test/ana\n",
      "ğŸ“‚ Moved hallulu/ks â†’ test/ks\n",
      "ğŸ“‚ Moved hallulu/r â†’ test/r\n",
      "ğŸ“‚ Moved hallulu/ta â†’ test/ta\n",
      "ğŸ“‚ Moved hallulu/da â†’ test/da\n",
      "ğŸ“‚ Moved hallulu/l â†’ test/l\n",
      "ğŸ“‚ Moved hallulu/thah â†’ test/thah\n",
      "ğŸ“‚ Moved hallulu/Ph â†’ test/Ph\n",
      "ğŸ“‚ Moved hallulu/g â†’ test/g\n",
      "ğŸ“‚ Moved hallulu/n â†’ test/n\n",
      "ğŸ“‚ Moved hallulu/tha â†’ test/tha\n",
      "ğŸ“‚ Moved hallulu/s â†’ test/s\n",
      "ğŸ“‚ Moved hallulu/rr â†’ test/rr\n",
      "ğŸ“‚ Moved hallulu/bh â†’ test/bh\n",
      "ğŸ“‚ Moved hallulu/sh â†’ test/sh\n",
      "ğŸ“‚ Moved hallulu/y â†’ test/y\n",
      "ğŸ“‚ Moved hallulu/dha â†’ test/dha\n",
      "ğŸ“‚ Moved hallulu/ka â†’ test/ka\n",
      "ğŸ“‚ Moved hallulu/b â†’ test/b\n",
      "ğŸ“‚ Moved hallulu/jha â†’ test/jha\n",
      "ğŸ“‚ Moved hallulu/h â†’ test/h\n",
      "ğŸ“‚ Moved hallulu/m â†’ test/m\n",
      "ğŸ“‚ Moved hallulu/jh â†’ test/jh\n",
      "\n",
      "âœ… Flattening complete! Now you have 52 folders directly inside each split (train, val, test).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "base_dir = \"/kaggle/working/dataset_70_20_10\"\n",
    "\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    split_path = os.path.join(base_dir, split)\n",
    "    for category in [\"achulu\", \"hallulu\"]:\n",
    "        cat_path = os.path.join(split_path, category)\n",
    "        if not os.path.exists(cat_path):\n",
    "            continue\n",
    "\n",
    "        for letter in os.listdir(cat_path):\n",
    "            src = os.path.join(cat_path, letter)\n",
    "            dst = os.path.join(split_path, letter)\n",
    "            if os.path.isdir(src):\n",
    "\n",
    "                if not os.path.exists(dst):\n",
    "                    shutil.move(src, dst)\n",
    "                else:\n",
    "\n",
    "                    for f in os.listdir(src):\n",
    "                        shutil.move(os.path.join(src, f), dst)\n",
    "                print(f\"ğŸ“‚ Moved {category}/{letter} â†’ {split}/{letter}\")\n",
    "\n",
    "        shutil.rmtree(cat_path, ignore_errors=True)\n",
    "\n",
    "print(\"\\nâœ… Flattening complete! Now you have 52 folders directly inside each split (train, val, test).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:53.279794Z",
     "iopub.status.busy": "2025-11-10T07:42:53.279552Z",
     "iopub.status.idle": "2025-11-10T07:42:53.287054Z",
     "shell.execute_reply": "2025-11-10T07:42:53.286502Z",
     "shell.execute_reply.started": "2025-11-10T07:42:53.279778Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:53.288816Z",
     "iopub.status.busy": "2025-11-10T07:42:53.288623Z",
     "iopub.status.idle": "2025-11-10T07:42:53.708110Z",
     "shell.execute_reply": "2025-11-10T07:42:53.707218Z",
     "shell.execute_reply.started": "2025-11-10T07:42:53.288801Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17843 images belonging to 51 classes.\n",
      "Found 5097 images belonging to 51 classes.\n",
      "Found 2552 images belonging to 51 classes.\n",
      "\n",
      "âœ… Detected 51 total classes.\n",
      "Sample class indices:\n",
      " [('P', 0), ('Ph', 1), ('a', 2), ('aa', 3), ('ah', 4), ('ai', 5), ('am', 6), ('ana', 7), ('ao', 8), ('b', 9)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = \"/kaggle/working/dataset_70_20_10\"\n",
    "train_dir = f\"{base_dir}/train\"\n",
    "val_dir = f\"{base_dir}/val\"\n",
    "test_dir = f\"{base_dir}/test\"\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "NUM_CLASSES = 51\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(\n",
    "    directory=val_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Detected {train_gen.num_classes} total classes.\")\n",
    "print(\"Sample class indices:\\n\", list(train_gen.class_indices.items())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:53.709704Z",
     "iopub.status.busy": "2025-11-10T07:42:53.709001Z",
     "iopub.status.idle": "2025-11-10T07:42:53.717287Z",
     "shell.execute_reply": "2025-11-10T07:42:53.716493Z",
     "shell.execute_reply.started": "2025-11-10T07:42:53.709683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inception_block(x, f1, f3, f5, f_pool, name=None):\n",
    "    conv1 = layers.Conv2D(f1, (1,1), padding='same', activation='relu',\n",
    "                          kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    conv3 = layers.Conv2D(f3[0], (1,1), padding='same', activation='relu')(x)\n",
    "    conv3 = layers.Conv2D(f3[1], (3,3), padding='same', activation='relu')(conv3)\n",
    "    conv5 = layers.Conv2D(f5[0], (1,1), padding='same', activation='relu')(x)\n",
    "    conv5 = layers.Conv2D(f5[1], (5,5), padding='same', activation='relu')(conv5)\n",
    "    pool = layers.MaxPooling2D((3,3), strides=(1,1), padding='same')(x)\n",
    "    pool = layers.Conv2D(f_pool, (1,1), padding='same', activation='relu')(pool)\n",
    "    return layers.Concatenate(axis=-1, name=name)([conv1, conv3, conv5, pool])\n",
    "\n",
    "\n",
    "def auxiliary_classifier(x, num_classes, name):\n",
    "    aux = layers.AveragePooling2D((2,2), strides=3)(x)\n",
    "    aux = layers.Conv2D(128, (1,1), activation='relu')(aux)\n",
    "    aux = layers.Flatten()(aux)\n",
    "    aux = layers.Dense(256, activation='relu')(aux)\n",
    "    aux = layers.Dropout(0.5)(aux)\n",
    "    aux = layers.Dense(num_classes, activation='softmax', name=name, dtype='float32')(aux)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:53.718333Z",
     "iopub.status.busy": "2025-11-10T07:42:53.718110Z",
     "iopub.status.idle": "2025-11-10T07:42:57.459160Z",
     "shell.execute_reply": "2025-11-10T07:42:57.458569Z",
     "shell.execute_reply.started": "2025-11-10T07:42:53.718315Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762760575.547944      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1762760575.548646      48 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(224,224,3))\n",
    "\n",
    "x = layers.Conv2D(32, (3,3), padding=\"same\")(inputs)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Conv2D(32, (3,3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Dropout(0.25)(x)\n",
    "\n",
    "x = layers.Conv2D(64, (3,3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Conv2D(64, (3,3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Dropout(0.30)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3,3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Conv2D(128, (3,3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Dropout(0.35)(x)\n",
    "\n",
    "x = layers.Conv2D(256, (3,3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Conv2D(256, (3,3), padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x); x = layers.Activation(\"relu\")(x)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Dropout(0.40)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:57.460109Z",
     "iopub.status.busy": "2025-11-10T07:42:57.459880Z",
     "iopub.status.idle": "2025-11-10T07:42:57.668830Z",
     "shell.execute_reply": "2025-11-10T07:42:57.668285Z",
     "shell.execute_reply.started": "2025-11-10T07:42:57.460082Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x = inception_block(x, 64, (96,128), (16,32), 32, name=\"inception_3a\")\n",
    "x = inception_block(x, 128, (128,192), (32,96), 64, name=\"inception_3b\")\n",
    "x = layers.MaxPooling2D((3,3), strides=2, padding='same')(x)\n",
    "\n",
    "aux_output = auxiliary_classifier(x, NUM_CLASSES, name=\"aux_output\")\n",
    "\n",
    "\n",
    "x = inception_block(x, 192, (96,208), (16,48), 64, name=\"inception_4a\")\n",
    "x = inception_block(x, 160, (112,224), (24,64), 64, name=\"inception_4b\")\n",
    "\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "main_output = layers.Dense(NUM_CLASSES, activation='softmax', name=\"main_output\", dtype='float32')(x)\n",
    "\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=[main_output, aux_output], name=\"CustomInceptionCNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:57.669683Z",
     "iopub.status.busy": "2025-11-10T07:42:57.669471Z",
     "iopub.status.idle": "2025-11-10T07:42:57.740057Z",
     "shell.execute_reply": "2025-11-10T07:42:57.739493Z",
     "shell.execute_reply.started": "2025-11-10T07:42:57.669667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CustomInceptionCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CustomInceptionCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> â”‚ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_2        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_3        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_4        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_5        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_2     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_6        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_7        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_3     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,672</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,112</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_4     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">110,720</span> â”‚ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,832</span> â”‚ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> â”‚ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_3a        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ inception_3a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> â”‚ inception_3a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_5     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ inception_3a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ inception_3a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">221,376</span> â”‚ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">76,896</span> â”‚ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_3b        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)              â”‚            â”‚ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ inception_3b[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">46,176</span> â”‚ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,696</span> â”‚ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_7     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">92,352</span> â”‚ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">179,920</span> â”‚ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">19,248</span> â”‚ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,784</span> â”‚ max_pooling2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_4a        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">57,456</span> â”‚ inception_4a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,312</span> â”‚ inception_4a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_8     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ inception_4a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ average_pooling2d   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,080</span> â”‚ inception_4a[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>) â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">226,016</span> â”‚ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">38,464</span> â”‚ conv2d_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> â”‚ max_pooling2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">61,568</span> â”‚ average_pooling2â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_4b        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ inception_4b[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ main_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">26,163</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ aux_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,107</span> â”‚ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚        \u001b[38;5;34m896\u001b[0m â”‚ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚        \u001b[38;5;34m128\u001b[0m â”‚ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚      \u001b[38;5;34m9,248\u001b[0m â”‚ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚        \u001b[38;5;34m128\u001b[0m â”‚ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚     \u001b[38;5;34m18,496\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_2        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚     \u001b[38;5;34m36,928\u001b[0m â”‚ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_3        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_1[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚     \u001b[38;5;34m73,856\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_4        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚    \u001b[38;5;34m147,584\u001b[0m â”‚ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_5        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_2     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_2[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚    \u001b[38;5;34m295,168\u001b[0m â”‚ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_6        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚    \u001b[38;5;34m590,080\u001b[0m â”‚ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_7        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mActivation\u001b[0m)        â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_3     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_3[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚     \u001b[38;5;34m24,672\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m96\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚      \u001b[38;5;34m4,112\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_4     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚     \u001b[38;5;34m16,448\u001b[0m â”‚ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚    \u001b[38;5;34m110,720\u001b[0m â”‚ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚     \u001b[38;5;34m12,832\u001b[0m â”‚ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚      \u001b[38;5;34m8,224\u001b[0m â”‚ max_pooling2d_4[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_3a        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ inception_3a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚      \u001b[38;5;34m8,224\u001b[0m â”‚ inception_3a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_5     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ inception_3a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚ \u001b[38;5;34m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚     \u001b[38;5;34m32,896\u001b[0m â”‚ inception_3a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚    \u001b[38;5;34m221,376\u001b[0m â”‚ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m192\u001b[0m)              â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚     \u001b[38;5;34m76,896\u001b[0m â”‚ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m96\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚     \u001b[38;5;34m16,448\u001b[0m â”‚ max_pooling2d_5[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_3b        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚ \u001b[38;5;34m480\u001b[0m)              â”‚            â”‚ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m480\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ inception_3b[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m96\u001b[0m)  â”‚     \u001b[38;5;34m46,176\u001b[0m â”‚ max_pooling2d_6[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)  â”‚      \u001b[38;5;34m7,696\u001b[0m â”‚ max_pooling2d_6[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_7     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m480\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_6[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m192\u001b[0m) â”‚     \u001b[38;5;34m92,352\u001b[0m â”‚ max_pooling2d_6[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m208\u001b[0m) â”‚    \u001b[38;5;34m179,920\u001b[0m â”‚ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m48\u001b[0m)  â”‚     \u001b[38;5;34m19,248\u001b[0m â”‚ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)  â”‚     \u001b[38;5;34m30,784\u001b[0m â”‚ max_pooling2d_7[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_4a        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m112\u001b[0m) â”‚     \u001b[38;5;34m57,456\u001b[0m â”‚ inception_4a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m24\u001b[0m)  â”‚     \u001b[38;5;34m12,312\u001b[0m â”‚ inception_4a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_8     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ inception_4a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ average_pooling2d   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m480\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling2d_6[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m160\u001b[0m) â”‚     \u001b[38;5;34m82,080\u001b[0m â”‚ inception_4a[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m224\u001b[0m) â”‚    \u001b[38;5;34m226,016\u001b[0m â”‚ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_31 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)  â”‚     \u001b[38;5;34m38,464\u001b[0m â”‚ conv2d_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)  â”‚     \u001b[38;5;34m32,832\u001b[0m â”‚ max_pooling2d_8[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m) â”‚     \u001b[38;5;34m61,568\u001b[0m â”‚ average_pooling2â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ inception_4b        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m) â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ conv2d_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ inception_4b[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚    \u001b[38;5;34m131,328\u001b[0m â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ main_output (\u001b[38;5;33mDense\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        â”‚     \u001b[38;5;34m26,163\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ aux_output (\u001b[38;5;33mDense\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        â”‚     \u001b[38;5;34m13,107\u001b[0m â”‚ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,799,342</span> (10.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,799,342\u001b[0m (10.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,797,422</span> (10.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,797,422\u001b[0m (10.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:57.740966Z",
     "iopub.status.busy": "2025-11-10T07:42:57.740739Z",
     "iopub.status.idle": "2025-11-10T07:42:58.073374Z",
     "shell.execute_reply": "2025-11-10T07:42:58.072571Z",
     "shell.execute_reply.started": "2025-11-10T07:42:57.740942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Input batch shape: (32, 224, 224, 3)\n",
      "âœ… Output keys: dict_keys(['main_output', 'aux_output'])\n",
      "âœ… Label shapes: (32, 51) (32, 51)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def make_multi_output_generator(single_gen):\n",
    "    while True:\n",
    "        x_batch, y_batch = next(single_gen)\n",
    "        x_batch = x_batch.astype('float32')\n",
    "        y_batch = y_batch.astype('float32')\n",
    "        yield (x_batch, {\"main_output\": y_batch, \"aux_output\": y_batch})\n",
    "\n",
    "train_gen_multi = make_multi_output_generator(train_gen)\n",
    "val_gen_multi   = make_multi_output_generator(val_gen)\n",
    "test_gen_multi  = make_multi_output_generator(test_gen)\n",
    "\n",
    "x, y = next(train_gen_multi)\n",
    "print(\"âœ… Input batch shape:\", x.shape)\n",
    "print(\"âœ… Output keys:\", y.keys())\n",
    "print(\"âœ… Label shapes:\", y['main_output'].shape, y['aux_output'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:58.074348Z",
     "iopub.status.busy": "2025-11-10T07:42:58.074145Z",
     "iopub.status.idle": "2025-11-10T07:42:58.088112Z",
     "shell.execute_reply": "2025-11-10T07:42:58.087311Z",
     "shell.execute_reply.started": "2025-11-10T07:42:58.074333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,      \n",
    "    decay_steps=3 * len(train_gen),  \n",
    "    decay_rate=0.9,                  \n",
    "    staircase=True                   \n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss={\n",
    "        \"main_output\": \"categorical_crossentropy\",\n",
    "        \"aux_output\": \"categorical_crossentropy\"\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"main_output\": 1.0,\n",
    "        \"aux_output\": 0.3\n",
    "    },\n",
    "    metrics={\n",
    "        \"main_output\": [\"accuracy\"],\n",
    "        \"aux_output\": [\"accuracy\"]\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:58.089277Z",
     "iopub.status.busy": "2025-11-10T07:42:58.089010Z",
     "iopub.status.idle": "2025-11-10T07:42:58.093963Z",
     "shell.execute_reply": "2025-11-10T07:42:58.093441Z",
     "shell.execute_reply.started": "2025-11-10T07:42:58.089255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=\"checkpoints/best_model.weights.h5\",\n",
    "        save_weights_only=True,\n",
    "        monitor=\"val_main_output_accuracy\",\n",
    "        save_best_only=True,\n",
    "        mode=\"max\",\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_main_output_loss\",\n",
    "        patience=15,               \n",
    "        min_delta=1e-4,            \n",
    "        restore_best_weights=True,\n",
    "        mode=\"min\",\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"val_main_output_loss\",\n",
    "        factor=0.8,\n",
    "        patience=6,\n",
    "        verbose=1,\n",
    "        mode=\"min\",\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:42:58.094868Z",
     "iopub.status.busy": "2025-11-10T07:42:58.094630Z",
     "iopub.status.idle": "2025-11-10T10:08:57.058613Z",
     "shell.execute_reply": "2025-11-10T10:08:57.057245Z",
     "shell.execute_reply.started": "2025-11-10T07:42:58.094847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting main training phase...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762760590.235739     134 service.cc:148] XLA service 0x7f34f80021b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762760590.237405     134 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762760590.237424     134 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762760592.176429     134 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1762760618.429945     134 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - aux_output_accuracy: 0.0281 - aux_output_loss: 4.0153 - loss: 5.2421 - main_output_accuracy: 0.0331 - main_output_loss: 3.9610\n",
      "Epoch 1: val_main_output_accuracy improved from -inf to 0.01982, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 380ms/step - aux_output_accuracy: 0.0281 - aux_output_loss: 4.0151 - loss: 5.2418 - main_output_accuracy: 0.0332 - main_output_loss: 3.9608 - val_aux_output_accuracy: 0.0210 - val_aux_output_loss: 3.9435 - val_loss: 5.3295 - val_main_output_accuracy: 0.0198 - val_main_output_loss: 4.0720 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - aux_output_accuracy: 0.0633 - aux_output_loss: 3.7085 - loss: 4.7305 - main_output_accuracy: 0.0718 - main_output_loss: 3.5482\n",
      "Epoch 2: val_main_output_accuracy improved from 0.01982 to 0.05371, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 326ms/step - aux_output_accuracy: 0.0633 - aux_output_loss: 3.7084 - loss: 4.7302 - main_output_accuracy: 0.0718 - main_output_loss: 3.5480 - val_aux_output_accuracy: 0.1047 - val_aux_output_loss: 3.6474 - val_loss: 4.8228 - val_main_output_accuracy: 0.0537 - val_main_output_loss: 3.6614 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - aux_output_accuracy: 0.1224 - aux_output_loss: 3.3198 - loss: 4.1606 - main_output_accuracy: 0.1390 - main_output_loss: 3.0981\n",
      "Epoch 3: val_main_output_accuracy improved from 0.05371 to 0.17402, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 327ms/step - aux_output_accuracy: 0.1225 - aux_output_loss: 3.3197 - loss: 4.1603 - main_output_accuracy: 0.1391 - main_output_loss: 3.0979 - val_aux_output_accuracy: 0.1549 - val_aux_output_loss: 3.2091 - val_loss: 4.0011 - val_main_output_accuracy: 0.1740 - val_main_output_loss: 2.9733 - learning_rate: 9.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - aux_output_accuracy: 0.1991 - aux_output_loss: 2.9511 - loss: 3.4251 - main_output_accuracy: 0.2846 - main_output_loss: 2.4750\n",
      "Epoch 4: val_main_output_accuracy improved from 0.17402 to 0.31387, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 324ms/step - aux_output_accuracy: 0.1992 - aux_output_loss: 2.9509 - loss: 3.4246 - main_output_accuracy: 0.2847 - main_output_loss: 2.4747 - val_aux_output_accuracy: 0.2562 - val_aux_output_loss: 2.8277 - val_loss: 3.3386 - val_main_output_accuracy: 0.3139 - val_main_output_loss: 2.4264 - learning_rate: 9.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - aux_output_accuracy: 0.3102 - aux_output_loss: 2.4493 - loss: 2.4838 - main_output_accuracy: 0.4936 - main_output_loss: 1.6855\n",
      "Epoch 5: val_main_output_accuracy improved from 0.31387 to 0.65020, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 317ms/step - aux_output_accuracy: 0.3102 - aux_output_loss: 2.4491 - loss: 2.4835 - main_output_accuracy: 0.4936 - main_output_loss: 1.6852 - val_aux_output_accuracy: 0.4850 - val_aux_output_loss: 2.0639 - val_loss: 2.0109 - val_main_output_accuracy: 0.6502 - val_main_output_loss: 1.3289 - learning_rate: 9.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.4142 - aux_output_loss: 2.0176 - loss: 1.8003 - main_output_accuracy: 0.6523 - main_output_loss: 1.1323\n",
      "Epoch 6: val_main_output_accuracy improved from 0.65020 to 0.72246, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 316ms/step - aux_output_accuracy: 0.4143 - aux_output_loss: 2.0175 - loss: 1.8001 - main_output_accuracy: 0.6523 - main_output_loss: 1.1322 - val_aux_output_accuracy: 0.5549 - val_aux_output_loss: 1.7931 - val_loss: 1.6799 - val_main_output_accuracy: 0.7225 - val_main_output_loss: 1.0799 - learning_rate: 8.1000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.4992 - aux_output_loss: 1.7137 - loss: 1.4302 - main_output_accuracy: 0.7336 - main_output_loss: 0.8543\n",
      "Epoch 7: val_main_output_accuracy improved from 0.72246 to 0.77324, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 316ms/step - aux_output_accuracy: 0.4992 - aux_output_loss: 1.7136 - loss: 1.4301 - main_output_accuracy: 0.7337 - main_output_loss: 0.8542 - val_aux_output_accuracy: 0.6031 - val_aux_output_loss: 1.5626 - val_loss: 1.3915 - val_main_output_accuracy: 0.7732 - val_main_output_loss: 0.8615 - learning_rate: 8.1000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - aux_output_accuracy: 0.5596 - aux_output_loss: 1.4721 - loss: 1.1790 - main_output_accuracy: 0.7897 - main_output_loss: 0.6763\n",
      "Epoch 8: val_main_output_accuracy did not improve from 0.77324\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 330ms/step - aux_output_accuracy: 0.5597 - aux_output_loss: 1.4720 - loss: 1.1789 - main_output_accuracy: 0.7898 - main_output_loss: 0.6763 - val_aux_output_accuracy: 0.5766 - val_aux_output_loss: 1.5081 - val_loss: 1.3724 - val_main_output_accuracy: 0.7410 - val_main_output_loss: 0.8594 - learning_rate: 8.1000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - aux_output_accuracy: 0.6106 - aux_output_loss: 1.3002 - loss: 1.0322 - main_output_accuracy: 0.8166 - main_output_loss: 0.5818\n",
      "Epoch 9: val_main_output_accuracy improved from 0.77324 to 0.87090, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 320ms/step - aux_output_accuracy: 0.6107 - aux_output_loss: 1.3001 - loss: 1.0321 - main_output_accuracy: 0.8166 - main_output_loss: 0.5817 - val_aux_output_accuracy: 0.7367 - val_aux_output_loss: 1.0419 - val_loss: 0.8562 - val_main_output_accuracy: 0.8709 - val_main_output_loss: 0.4838 - learning_rate: 7.2900e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - aux_output_accuracy: 0.6584 - aux_output_loss: 1.1325 - loss: 0.8582 - main_output_accuracy: 0.8561 - main_output_loss: 0.4587\n",
      "Epoch 10: val_main_output_accuracy did not improve from 0.87090\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 320ms/step - aux_output_accuracy: 0.6584 - aux_output_loss: 1.1325 - loss: 0.8582 - main_output_accuracy: 0.8561 - main_output_loss: 0.4587 - val_aux_output_accuracy: 0.5410 - val_aux_output_loss: 1.5699 - val_loss: 1.6272 - val_main_output_accuracy: 0.6687 - val_main_output_loss: 1.0970 - learning_rate: 7.2900e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - aux_output_accuracy: 0.6831 - aux_output_loss: 1.0369 - loss: 0.7964 - main_output_accuracy: 0.8672 - main_output_loss: 0.4262\n",
      "Epoch 11: val_main_output_accuracy improved from 0.87090 to 0.88457, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 319ms/step - aux_output_accuracy: 0.6831 - aux_output_loss: 1.0369 - loss: 0.7964 - main_output_accuracy: 0.8672 - main_output_loss: 0.4262 - val_aux_output_accuracy: 0.7674 - val_aux_output_loss: 0.8542 - val_loss: 0.7156 - val_main_output_accuracy: 0.8846 - val_main_output_loss: 0.4006 - learning_rate: 7.2900e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - aux_output_accuracy: 0.7090 - aux_output_loss: 0.9610 - loss: 0.7240 - main_output_accuracy: 0.8807 - main_output_loss: 0.3772\n",
      "Epoch 12: val_main_output_accuracy did not improve from 0.88457\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 318ms/step - aux_output_accuracy: 0.7090 - aux_output_loss: 0.9610 - loss: 0.7240 - main_output_accuracy: 0.8807 - main_output_loss: 0.3772 - val_aux_output_accuracy: 0.7398 - val_aux_output_loss: 0.9167 - val_loss: 0.7839 - val_main_output_accuracy: 0.8639 - val_main_output_loss: 0.4508 - learning_rate: 6.5610e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - aux_output_accuracy: 0.7283 - aux_output_loss: 0.8742 - loss: 0.6495 - main_output_accuracy: 0.8957 - main_output_loss: 0.3293\n",
      "Epoch 13: val_main_output_accuracy improved from 0.88457 to 0.88906, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 320ms/step - aux_output_accuracy: 0.7283 - aux_output_loss: 0.8742 - loss: 0.6495 - main_output_accuracy: 0.8957 - main_output_loss: 0.3293 - val_aux_output_accuracy: 0.8256 - val_aux_output_loss: 0.6759 - val_loss: 0.6361 - val_main_output_accuracy: 0.8891 - val_main_output_loss: 0.3757 - learning_rate: 6.5610e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - aux_output_accuracy: 0.7466 - aux_output_loss: 0.8160 - loss: 0.6125 - main_output_accuracy: 0.9017 - main_output_loss: 0.3103\n",
      "Epoch 14: val_main_output_accuracy improved from 0.88906 to 0.90898, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 319ms/step - aux_output_accuracy: 0.7466 - aux_output_loss: 0.8159 - loss: 0.6125 - main_output_accuracy: 0.9017 - main_output_loss: 0.3103 - val_aux_output_accuracy: 0.8211 - val_aux_output_loss: 0.6564 - val_loss: 0.5912 - val_main_output_accuracy: 0.9090 - val_main_output_loss: 0.3372 - learning_rate: 6.5610e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.7658 - aux_output_loss: 0.7473 - loss: 0.5669 - main_output_accuracy: 0.9094 - main_output_loss: 0.2857\n",
      "Epoch 15: val_main_output_accuracy did not improve from 0.90898\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 315ms/step - aux_output_accuracy: 0.7658 - aux_output_loss: 0.7473 - loss: 0.5669 - main_output_accuracy: 0.9094 - main_output_loss: 0.2857 - val_aux_output_accuracy: 0.8051 - val_aux_output_loss: 0.6881 - val_loss: 0.5894 - val_main_output_accuracy: 0.9072 - val_main_output_loss: 0.3264 - learning_rate: 5.9049e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - aux_output_accuracy: 0.7846 - aux_output_loss: 0.7015 - loss: 0.5105 - main_output_accuracy: 0.9199 - main_output_loss: 0.2435\n",
      "Epoch 16: val_main_output_accuracy did not improve from 0.90898\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 322ms/step - aux_output_accuracy: 0.7846 - aux_output_loss: 0.7015 - loss: 0.5105 - main_output_accuracy: 0.9199 - main_output_loss: 0.2435 - val_aux_output_accuracy: 0.7682 - val_aux_output_loss: 0.8256 - val_loss: 0.7615 - val_main_output_accuracy: 0.8568 - val_main_output_loss: 0.4576 - learning_rate: 5.9049e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - aux_output_accuracy: 0.7912 - aux_output_loss: 0.6694 - loss: 0.4961 - main_output_accuracy: 0.9225 - main_output_loss: 0.2391\n",
      "Epoch 17: val_main_output_accuracy improved from 0.90898 to 0.94121, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 326ms/step - aux_output_accuracy: 0.7912 - aux_output_loss: 0.6694 - loss: 0.4960 - main_output_accuracy: 0.9225 - main_output_loss: 0.2391 - val_aux_output_accuracy: 0.8602 - val_aux_output_loss: 0.5082 - val_loss: 0.4158 - val_main_output_accuracy: 0.9412 - val_main_output_loss: 0.2075 - learning_rate: 5.9049e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.8024 - aux_output_loss: 0.6293 - loss: 0.4732 - main_output_accuracy: 0.9263 - main_output_loss: 0.2287\n",
      "Epoch 18: val_main_output_accuracy did not improve from 0.94121\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 315ms/step - aux_output_accuracy: 0.8024 - aux_output_loss: 0.6293 - loss: 0.4732 - main_output_accuracy: 0.9263 - main_output_loss: 0.2287 - val_aux_output_accuracy: 0.8613 - val_aux_output_loss: 0.4880 - val_loss: 0.4099 - val_main_output_accuracy: 0.9408 - val_main_output_loss: 0.2081 - learning_rate: 5.3144e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.8191 - aux_output_loss: 0.5693 - loss: 0.4299 - main_output_accuracy: 0.9338 - main_output_loss: 0.2037\n",
      "Epoch 19: val_main_output_accuracy improved from 0.94121 to 0.94134, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 316ms/step - aux_output_accuracy: 0.8191 - aux_output_loss: 0.5693 - loss: 0.4299 - main_output_accuracy: 0.9338 - main_output_loss: 0.2037 - val_aux_output_accuracy: 0.8738 - val_aux_output_loss: 0.4432 - val_loss: 0.3759 - val_main_output_accuracy: 0.9413 - val_main_output_loss: 0.1866 - learning_rate: 5.3144e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - aux_output_accuracy: 0.8246 - aux_output_loss: 0.5361 - loss: 0.4036 - main_output_accuracy: 0.9381 - main_output_loss: 0.1878\n",
      "Epoch 20: val_main_output_accuracy did not improve from 0.94134\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 316ms/step - aux_output_accuracy: 0.8246 - aux_output_loss: 0.5361 - loss: 0.4036 - main_output_accuracy: 0.9381 - main_output_loss: 0.1878 - val_aux_output_accuracy: 0.7638 - val_aux_output_loss: 0.7732 - val_loss: 0.6829 - val_main_output_accuracy: 0.8782 - val_main_output_loss: 0.3941 - learning_rate: 5.3144e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - aux_output_accuracy: 0.8285 - aux_output_loss: 0.5283 - loss: 0.3859 - main_output_accuracy: 0.9420 - main_output_loss: 0.1728\n",
      "Epoch 21: val_main_output_accuracy did not improve from 0.94134\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 318ms/step - aux_output_accuracy: 0.8285 - aux_output_loss: 0.5283 - loss: 0.3859 - main_output_accuracy: 0.9420 - main_output_loss: 0.1728 - val_aux_output_accuracy: 0.8360 - val_aux_output_loss: 0.5396 - val_loss: 0.4401 - val_main_output_accuracy: 0.9280 - val_main_output_loss: 0.2226 - learning_rate: 4.7830e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - aux_output_accuracy: 0.8366 - aux_output_loss: 0.5087 - loss: 0.3744 - main_output_accuracy: 0.9440 - main_output_loss: 0.1675\n",
      "Epoch 22: val_main_output_accuracy improved from 0.94134 to 0.95056, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 318ms/step - aux_output_accuracy: 0.8366 - aux_output_loss: 0.5087 - loss: 0.3744 - main_output_accuracy: 0.9440 - main_output_loss: 0.1675 - val_aux_output_accuracy: 0.8872 - val_aux_output_loss: 0.3848 - val_loss: 0.3309 - val_main_output_accuracy: 0.9506 - val_main_output_loss: 0.1610 - learning_rate: 4.7830e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - aux_output_accuracy: 0.8513 - aux_output_loss: 0.4655 - loss: 0.3443 - main_output_accuracy: 0.9524 - main_output_loss: 0.1507\n",
      "Epoch 23: val_main_output_accuracy did not improve from 0.95056\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 318ms/step - aux_output_accuracy: 0.8513 - aux_output_loss: 0.4655 - loss: 0.3443 - main_output_accuracy: 0.9524 - main_output_loss: 0.1507 - val_aux_output_accuracy: 0.8748 - val_aux_output_loss: 0.4322 - val_loss: 0.3730 - val_main_output_accuracy: 0.9423 - val_main_output_loss: 0.1886 - learning_rate: 4.7830e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - aux_output_accuracy: 0.8583 - aux_output_loss: 0.4512 - loss: 0.3294 - main_output_accuracy: 0.9529 - main_output_loss: 0.1405\n",
      "Epoch 24: val_main_output_accuracy did not improve from 0.95056\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 319ms/step - aux_output_accuracy: 0.8583 - aux_output_loss: 0.4513 - loss: 0.3294 - main_output_accuracy: 0.9529 - main_output_loss: 0.1405 - val_aux_output_accuracy: 0.8603 - val_aux_output_loss: 0.4600 - val_loss: 0.4099 - val_main_output_accuracy: 0.9288 - val_main_output_loss: 0.2170 - learning_rate: 4.3047e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.8613 - aux_output_loss: 0.4384 - loss: 0.3259 - main_output_accuracy: 0.9522 - main_output_loss: 0.1411\n",
      "Epoch 25: val_main_output_accuracy did not improve from 0.95056\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 314ms/step - aux_output_accuracy: 0.8613 - aux_output_loss: 0.4384 - loss: 0.3259 - main_output_accuracy: 0.9522 - main_output_loss: 0.1411 - val_aux_output_accuracy: 0.8723 - val_aux_output_loss: 0.4438 - val_loss: 0.3848 - val_main_output_accuracy: 0.9386 - val_main_output_loss: 0.1973 - learning_rate: 4.3047e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - aux_output_accuracy: 0.8655 - aux_output_loss: 0.4221 - loss: 0.3058 - main_output_accuracy: 0.9567 - main_output_loss: 0.1262\n",
      "Epoch 26: val_main_output_accuracy did not improve from 0.95056\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 318ms/step - aux_output_accuracy: 0.8655 - aux_output_loss: 0.4221 - loss: 0.3058 - main_output_accuracy: 0.9567 - main_output_loss: 0.1262 - val_aux_output_accuracy: 0.8880 - val_aux_output_loss: 0.3784 - val_loss: 0.3258 - val_main_output_accuracy: 0.9488 - val_main_output_loss: 0.1585 - learning_rate: 4.3047e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.8744 - aux_output_loss: 0.3920 - loss: 0.2887 - main_output_accuracy: 0.9602 - main_output_loss: 0.1184\n",
      "Epoch 27: val_main_output_accuracy improved from 0.95056 to 0.95703, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 315ms/step - aux_output_accuracy: 0.8744 - aux_output_loss: 0.3920 - loss: 0.2887 - main_output_accuracy: 0.9602 - main_output_loss: 0.1184 - val_aux_output_accuracy: 0.8890 - val_aux_output_loss: 0.3684 - val_loss: 0.3091 - val_main_output_accuracy: 0.9570 - val_main_output_loss: 0.1456 - learning_rate: 3.8742e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - aux_output_accuracy: 0.8753 - aux_output_loss: 0.3794 - loss: 0.2764 - main_output_accuracy: 0.9645 - main_output_loss: 0.1102\n",
      "Epoch 28: val_main_output_accuracy did not improve from 0.95703\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 320ms/step - aux_output_accuracy: 0.8753 - aux_output_loss: 0.3794 - loss: 0.2764 - main_output_accuracy: 0.9645 - main_output_loss: 0.1102 - val_aux_output_accuracy: 0.8984 - val_aux_output_loss: 0.3466 - val_loss: 0.3115 - val_main_output_accuracy: 0.9511 - val_main_output_loss: 0.1544 - learning_rate: 3.8742e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - aux_output_accuracy: 0.8779 - aux_output_loss: 0.3723 - loss: 0.2790 - main_output_accuracy: 0.9633 - main_output_loss: 0.1153\n",
      "Epoch 29: val_main_output_accuracy did not improve from 0.95703\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 319ms/step - aux_output_accuracy: 0.8779 - aux_output_loss: 0.3723 - loss: 0.2790 - main_output_accuracy: 0.9633 - main_output_loss: 0.1153 - val_aux_output_accuracy: 0.8803 - val_aux_output_loss: 0.4019 - val_loss: 0.3808 - val_main_output_accuracy: 0.9339 - val_main_output_loss: 0.2071 - learning_rate: 3.8742e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - aux_output_accuracy: 0.8812 - aux_output_loss: 0.3631 - loss: 0.2608 - main_output_accuracy: 0.9665 - main_output_loss: 0.1000\n",
      "Epoch 30: val_main_output_accuracy did not improve from 0.95703\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 321ms/step - aux_output_accuracy: 0.8812 - aux_output_loss: 0.3631 - loss: 0.2608 - main_output_accuracy: 0.9665 - main_output_loss: 0.1000 - val_aux_output_accuracy: 0.8966 - val_aux_output_loss: 0.3476 - val_loss: 0.3220 - val_main_output_accuracy: 0.9506 - val_main_output_loss: 0.1653 - learning_rate: 3.4868e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - aux_output_accuracy: 0.8911 - aux_output_loss: 0.3354 - loss: 0.2488 - main_output_accuracy: 0.9680 - main_output_loss: 0.0967\n",
      "Epoch 31: val_main_output_accuracy improved from 0.95703 to 0.95998, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 314ms/step - aux_output_accuracy: 0.8911 - aux_output_loss: 0.3354 - loss: 0.2489 - main_output_accuracy: 0.9680 - main_output_loss: 0.0967 - val_aux_output_accuracy: 0.9066 - val_aux_output_loss: 0.3132 - val_loss: 0.2734 - val_main_output_accuracy: 0.9600 - val_main_output_loss: 0.1273 - learning_rate: 3.4868e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.8857 - aux_output_loss: 0.3495 - loss: 0.2563 - main_output_accuracy: 0.9677 - main_output_loss: 0.1001\n",
      "Epoch 32: val_main_output_accuracy did not improve from 0.95998\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 314ms/step - aux_output_accuracy: 0.8857 - aux_output_loss: 0.3495 - loss: 0.2563 - main_output_accuracy: 0.9677 - main_output_loss: 0.1001 - val_aux_output_accuracy: 0.9054 - val_aux_output_loss: 0.3228 - val_loss: 0.3091 - val_main_output_accuracy: 0.9508 - val_main_output_loss: 0.1603 - learning_rate: 3.4868e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - aux_output_accuracy: 0.8894 - aux_output_loss: 0.3310 - loss: 0.2406 - main_output_accuracy: 0.9686 - main_output_loss: 0.0902\n",
      "Epoch 33: val_main_output_accuracy did not improve from 0.95998\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 312ms/step - aux_output_accuracy: 0.8894 - aux_output_loss: 0.3310 - loss: 0.2406 - main_output_accuracy: 0.9686 - main_output_loss: 0.0902 - val_aux_output_accuracy: 0.8976 - val_aux_output_loss: 0.3392 - val_loss: 0.3170 - val_main_output_accuracy: 0.9464 - val_main_output_loss: 0.1632 - learning_rate: 3.1381e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - aux_output_accuracy: 0.9010 - aux_output_loss: 0.3169 - loss: 0.2308 - main_output_accuracy: 0.9717 - main_output_loss: 0.0849\n",
      "Epoch 34: val_main_output_accuracy did not improve from 0.95998\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 311ms/step - aux_output_accuracy: 0.9010 - aux_output_loss: 0.3169 - loss: 0.2308 - main_output_accuracy: 0.9717 - main_output_loss: 0.0849 - val_aux_output_accuracy: 0.8462 - val_aux_output_loss: 0.5009 - val_loss: 0.4781 - val_main_output_accuracy: 0.9147 - val_main_output_loss: 0.2754 - learning_rate: 3.1381e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - aux_output_accuracy: 0.8940 - aux_output_loss: 0.3290 - loss: 0.2382 - main_output_accuracy: 0.9694 - main_output_loss: 0.0889\n",
      "Epoch 35: val_main_output_accuracy did not improve from 0.95998\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 319ms/step - aux_output_accuracy: 0.8940 - aux_output_loss: 0.3290 - loss: 0.2382 - main_output_accuracy: 0.9694 - main_output_loss: 0.0889 - val_aux_output_accuracy: 0.8980 - val_aux_output_loss: 0.3322 - val_loss: 0.3083 - val_main_output_accuracy: 0.9474 - val_main_output_loss: 0.1572 - learning_rate: 3.1381e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - aux_output_accuracy: 0.9045 - aux_output_loss: 0.2883 - loss: 0.2199 - main_output_accuracy: 0.9693 - main_output_loss: 0.0830\n",
      "Epoch 36: val_main_output_accuracy did not improve from 0.95998\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 317ms/step - aux_output_accuracy: 0.9045 - aux_output_loss: 0.2883 - loss: 0.2199 - main_output_accuracy: 0.9693 - main_output_loss: 0.0830 - val_aux_output_accuracy: 0.8852 - val_aux_output_loss: 0.3780 - val_loss: 0.3385 - val_main_output_accuracy: 0.9474 - val_main_output_loss: 0.1741 - learning_rate: 2.8243e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.9070 - aux_output_loss: 0.2782 - loss: 0.2131 - main_output_accuracy: 0.9724 - main_output_loss: 0.0795\n",
      "Epoch 37: val_main_output_accuracy improved from 0.95998 to 0.96606, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 316ms/step - aux_output_accuracy: 0.9070 - aux_output_loss: 0.2782 - loss: 0.2131 - main_output_accuracy: 0.9724 - main_output_loss: 0.0795 - val_aux_output_accuracy: 0.9160 - val_aux_output_loss: 0.2770 - val_loss: 0.2429 - val_main_output_accuracy: 0.9661 - val_main_output_loss: 0.1090 - learning_rate: 2.8243e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - aux_output_accuracy: 0.9074 - aux_output_loss: 0.2865 - loss: 0.2128 - main_output_accuracy: 0.9744 - main_output_loss: 0.0769\n",
      "Epoch 38: val_main_output_accuracy did not improve from 0.96606\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 317ms/step - aux_output_accuracy: 0.9074 - aux_output_loss: 0.2865 - loss: 0.2128 - main_output_accuracy: 0.9744 - main_output_loss: 0.0769 - val_aux_output_accuracy: 0.8387 - val_aux_output_loss: 0.5195 - val_loss: 0.4440 - val_main_output_accuracy: 0.9258 - val_main_output_loss: 0.2369 - learning_rate: 2.8243e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - aux_output_accuracy: 0.9118 - aux_output_loss: 0.2704 - loss: 0.2036 - main_output_accuracy: 0.9757 - main_output_loss: 0.0727\n",
      "Epoch 39: val_main_output_accuracy did not improve from 0.96606\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 315ms/step - aux_output_accuracy: 0.9118 - aux_output_loss: 0.2705 - loss: 0.2036 - main_output_accuracy: 0.9757 - main_output_loss: 0.0727 - val_aux_output_accuracy: 0.9062 - val_aux_output_loss: 0.3116 - val_loss: 0.2843 - val_main_output_accuracy: 0.9549 - val_main_output_loss: 0.1403 - learning_rate: 2.5419e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - aux_output_accuracy: 0.9112 - aux_output_loss: 0.2609 - loss: 0.1933 - main_output_accuracy: 0.9765 - main_output_loss: 0.0655\n",
      "Epoch 40: val_main_output_accuracy did not improve from 0.96606\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 310ms/step - aux_output_accuracy: 0.9111 - aux_output_loss: 0.2609 - loss: 0.1933 - main_output_accuracy: 0.9765 - main_output_loss: 0.0655 - val_aux_output_accuracy: 0.9066 - val_aux_output_loss: 0.3109 - val_loss: 0.2713 - val_main_output_accuracy: 0.9592 - val_main_output_loss: 0.1279 - learning_rate: 2.5419e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - aux_output_accuracy: 0.9094 - aux_output_loss: 0.2682 - loss: 0.1983 - main_output_accuracy: 0.9765 - main_output_loss: 0.0685\n",
      "Epoch 41: val_main_output_accuracy improved from 0.96606 to 0.96724, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 316ms/step - aux_output_accuracy: 0.9094 - aux_output_loss: 0.2682 - loss: 0.1983 - main_output_accuracy: 0.9765 - main_output_loss: 0.0685 - val_aux_output_accuracy: 0.9307 - val_aux_output_loss: 0.2365 - val_loss: 0.2226 - val_main_output_accuracy: 0.9672 - val_main_output_loss: 0.1018 - learning_rate: 2.5419e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - aux_output_accuracy: 0.9081 - aux_output_loss: 0.2643 - loss: 0.1982 - main_output_accuracy: 0.9763 - main_output_loss: 0.0697\n",
      "Epoch 42: val_main_output_accuracy did not improve from 0.96724\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 313ms/step - aux_output_accuracy: 0.9081 - aux_output_loss: 0.2643 - loss: 0.1982 - main_output_accuracy: 0.9763 - main_output_loss: 0.0697 - val_aux_output_accuracy: 0.9254 - val_aux_output_loss: 0.2460 - val_loss: 0.2231 - val_main_output_accuracy: 0.9655 - val_main_output_loss: 0.0996 - learning_rate: 2.2877e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - aux_output_accuracy: 0.9146 - aux_output_loss: 0.2508 - loss: 0.1817 - main_output_accuracy: 0.9813 - main_output_loss: 0.0574\n",
      "Epoch 43: val_main_output_accuracy improved from 0.96724 to 0.97096, saving model to checkpoints/best_model.weights.h5\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 322ms/step - aux_output_accuracy: 0.9146 - aux_output_loss: 0.2508 - loss: 0.1817 - main_output_accuracy: 0.9813 - main_output_loss: 0.0574 - val_aux_output_accuracy: 0.9280 - val_aux_output_loss: 0.2446 - val_loss: 0.2187 - val_main_output_accuracy: 0.9710 - val_main_output_loss: 0.0958 - learning_rate: 2.2877e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - aux_output_accuracy: 0.9155 - aux_output_loss: 0.2529 - loss: 0.1822 - main_output_accuracy: 0.9805 - main_output_loss: 0.0576\n",
      "Epoch 44: val_main_output_accuracy did not improve from 0.97096\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 318ms/step - aux_output_accuracy: 0.9155 - aux_output_loss: 0.2529 - loss: 0.1822 - main_output_accuracy: 0.9805 - main_output_loss: 0.0576 - val_aux_output_accuracy: 0.9217 - val_aux_output_loss: 0.2677 - val_loss: 0.2441 - val_main_output_accuracy: 0.9633 - val_main_output_loss: 0.1143 - learning_rate: 2.2877e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - aux_output_accuracy: 0.9166 - aux_output_loss: 0.2457 - loss: 0.1850 - main_output_accuracy: 0.9783 - main_output_loss: 0.0627\n",
      "Epoch 45: val_main_output_accuracy did not improve from 0.97096\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 318ms/step - aux_output_accuracy: 0.9166 - aux_output_loss: 0.2457 - loss: 0.1850 - main_output_accuracy: 0.9783 - main_output_loss: 0.0627 - val_aux_output_accuracy: 0.9149 - val_aux_output_loss: 0.2766 - val_loss: 0.2532 - val_main_output_accuracy: 0.9594 - val_main_output_loss: 0.1209 - learning_rate: 2.0589e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - aux_output_accuracy: 0.9259 - aux_output_loss: 0.2305 - loss: 0.1788 - main_output_accuracy: 0.9805 - main_output_loss: 0.0611\n",
      "Epoch 46: val_main_output_accuracy did not improve from 0.97096\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 319ms/step - aux_output_accuracy: 0.9259 - aux_output_loss: 0.2305 - loss: 0.1787 - main_output_accuracy: 0.9805 - main_output_loss: 0.0611 - val_aux_output_accuracy: 0.9286 - val_aux_output_loss: 0.2356 - val_loss: 0.2159 - val_main_output_accuracy: 0.9686 - val_main_output_loss: 0.0962 - learning_rate: 2.0589e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - aux_output_accuracy: 0.9222 - aux_output_loss: 0.2295 - loss: 0.1732 - main_output_accuracy: 0.9808 - main_output_loss: 0.0561\n",
      "Epoch 47: val_main_output_accuracy did not improve from 0.97096\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 317ms/step - aux_output_accuracy: 0.9222 - aux_output_loss: 0.2295 - loss: 0.1732 - main_output_accuracy: 0.9808 - main_output_loss: 0.0561 - val_aux_output_accuracy: 0.9217 - val_aux_output_loss: 0.2567 - val_loss: 0.2285 - val_main_output_accuracy: 0.9672 - val_main_output_loss: 0.1028 - learning_rate: 2.0589e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - aux_output_accuracy: 0.9209 - aux_output_loss: 0.2351 - loss: 0.1722 - main_output_accuracy: 0.9816 - main_output_loss: 0.0535\n",
      "Epoch 48: val_main_output_accuracy did not improve from 0.97096\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 316ms/step - aux_output_accuracy: 0.9209 - aux_output_loss: 0.2351 - loss: 0.1722 - main_output_accuracy: 0.9816 - main_output_loss: 0.0535 - val_aux_output_accuracy: 0.9200 - val_aux_output_loss: 0.2564 - val_loss: 0.2352 - val_main_output_accuracy: 0.9629 - val_main_output_loss: 0.1094 - learning_rate: 1.8530e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - aux_output_accuracy: 0.9208 - aux_output_loss: 0.2368 - loss: 0.1752 - main_output_accuracy: 0.9816 - main_output_loss: 0.0561\n",
      "Epoch 49: val_main_output_accuracy did not improve from 0.97096\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/3107689474.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ğŸš€ Starting main training phase...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_gen_multi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen_multi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mlearning_rate\u001b[0;34m(self, learning_rate)\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             ):\n\u001b[0;32m--> 636\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m    637\u001b[0m                     \u001b[0;34m\"This optimizer was created with a `LearningRateSchedule`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m                     \u001b[0;34m\" object as its `learning_rate` constructor argument, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: This optimizer was created with a `LearningRateSchedule` object as its `learning_rate` constructor argument, hence its learning rate is not settable. If you need the learning rate to be settable, you should instantiate the optimizer with a float `learning_rate` argument."
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ Starting main training phase...\")\n",
    "history = model.fit(\n",
    "    train_gen_multi,\n",
    "    validation_data=val_gen_multi,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=50,                     \n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-10T11:59:34.065Z",
     "iopub.execute_input": "2025-11-10T10:26:18.425382Z",
     "iopub.status.busy": "2025-11-10T10:26:18.425103Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‰ Fine-tuning main branch only...\n",
      "Epoch 1/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 349ms/step - accuracy: 0.9696 - loss: 0.1379 - val_accuracy: 0.8703 - val_loss: 0.4960\n",
      "Epoch 2/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 321ms/step - accuracy: 0.9700 - loss: 0.1400 - val_accuracy: 0.9372 - val_loss: 0.2563\n",
      "Epoch 3/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 323ms/step - accuracy: 0.9740 - loss: 0.1292 - val_accuracy: 0.9235 - val_loss: 0.3050\n",
      "Epoch 4/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 327ms/step - accuracy: 0.9742 - loss: 0.1226 - val_accuracy: 0.9366 - val_loss: 0.2524\n",
      "Epoch 5/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 321ms/step - accuracy: 0.9714 - loss: 0.1292 - val_accuracy: 0.9492 - val_loss: 0.2082\n",
      "Epoch 6/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 319ms/step - accuracy: 0.9744 - loss: 0.1194 - val_accuracy: 0.9619 - val_loss: 0.1632\n",
      "Epoch 7/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 317ms/step - accuracy: 0.9748 - loss: 0.1205 - val_accuracy: 0.9382 - val_loss: 0.2586\n",
      "Epoch 8/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 323ms/step - accuracy: 0.9761 - loss: 0.1208 - val_accuracy: 0.7865 - val_loss: 0.7755\n",
      "Epoch 9/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 321ms/step - accuracy: 0.9752 - loss: 0.1178 - val_accuracy: 0.9304 - val_loss: 0.2614\n",
      "Epoch 10/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 323ms/step - accuracy: 0.9755 - loss: 0.1162 - val_accuracy: 0.9615 - val_loss: 0.1627\n",
      "Epoch 11/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 320ms/step - accuracy: 0.9827 - loss: 0.1001 - val_accuracy: 0.9670 - val_loss: 0.1449\n",
      "Epoch 12/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 325ms/step - accuracy: 0.9781 - loss: 0.1070 - val_accuracy: 0.9400 - val_loss: 0.2353\n",
      "Epoch 13/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 318ms/step - accuracy: 0.9797 - loss: 0.1043 - val_accuracy: 0.9205 - val_loss: 0.2849\n",
      "Epoch 14/15\n",
      "\u001b[1m558/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 320ms/step - accuracy: 0.9782 - loss: 0.1035 - val_accuracy: 0.9561 - val_loss: 0.1796\n",
      "Epoch 15/15\n",
      "\u001b[1m467/558\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m28s\u001b[0m 312ms/step - accuracy: 0.9780 - loss: 0.1084"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "model.load_weights(\"checkpoints/best_model.weights.h5\")\n",
    "\n",
    "main_output = model.get_layer(\"main_output\").output\n",
    "model_finetune = Model(inputs=model.input, outputs=main_output, name=\"MainOutputOnly\")\n",
    "\n",
    "\n",
    "model_finetune.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "print(\"ğŸ“‰ Fine-tuning main branch only...\")\n",
    "\n",
    "history_finetune = model_finetune.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    steps_per_epoch=len(train_gen),\n",
    "    validation_steps=len(val_gen),\n",
    "    epochs=15,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T12:53:02.143678Z",
     "iopub.status.busy": "2025-11-10T12:53:02.143104Z",
     "iopub.status.idle": "2025-11-10T12:53:02.209302Z",
     "shell.execute_reply": "2025-11-10T12:53:02.208397Z",
     "shell.execute_reply.started": "2025-11-10T12:53:02.143653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/3060604215.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/final_inception_telugu_finetuned.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nâœ… Fine-tuned model saved at: /kaggle/working/final_inception_telugu_finetuned.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"/kaggle/working/final_inception_telugu_finetuned.h5\")\n",
    "print(\"\\nâœ… Fine-tuned model saved at: /kaggle/working/final_inception_telugu_finetuned.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T12:56:08.902405Z",
     "iopub.status.busy": "2025-11-10T12:56:08.901840Z",
     "iopub.status.idle": "2025-11-10T12:56:09.335834Z",
     "shell.execute_reply": "2025-11-10T12:56:09.335210Z",
     "shell.execute_reply.started": "2025-11-10T12:56:08.902348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Clean data extracted for 48 epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re, matplotlib.pyplot as plt\n",
    "\n",
    "log_text = \"\"\"558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 352ms/step - aux_output_accuracy: 0.0281 - aux_output_loss: 4.0153 - loss: 5.2421 - main_output_accuracy: 0.0331 - main_output_loss: 3.9610\n",
    "Epoch 1: val_main_output_accuracy improved from -inf to 0.01982, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 251s 380ms/step - aux_output_accuracy: 0.0281 - aux_output_loss: 4.0151 - loss: 5.2418 - main_output_accuracy: 0.0332 - main_output_loss: 3.9608 - val_aux_output_accuracy: 0.0210 - val_aux_output_loss: 3.9435 - val_loss: 5.3295 - val_main_output_accuracy: 0.0198 - val_main_output_loss: 4.0720 - learning_rate: 1.0000e-04\n",
    "Epoch 2/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 311ms/step - aux_output_accuracy: 0.0633 - aux_output_loss: 3.7085 - loss: 4.7305 - main_output_accuracy: 0.0718 - main_output_loss: 3.5482\n",
    "Epoch 2: val_main_output_accuracy improved from 0.01982 to 0.05371, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 182s 326ms/step - aux_output_accuracy: 0.0633 - aux_output_loss: 3.7084 - loss: 4.7302 - main_output_accuracy: 0.0718 - main_output_loss: 3.5480 - val_aux_output_accuracy: 0.1047 - val_aux_output_loss: 3.6474 - val_loss: 4.8228 - val_main_output_accuracy: 0.0537 - val_main_output_loss: 3.6614 - learning_rate: 1.0000e-04\n",
    "Epoch 3/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 312ms/step - aux_output_accuracy: 0.1224 - aux_output_loss: 3.3198 - loss: 4.1606 - main_output_accuracy: 0.1390 - main_output_loss: 3.0981\n",
    "Epoch 3: val_main_output_accuracy improved from 0.05371 to 0.17402, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 182s 327ms/step - aux_output_accuracy: 0.1225 - aux_output_loss: 3.3197 - loss: 4.1603 - main_output_accuracy: 0.1391 - main_output_loss: 3.0979 - val_aux_output_accuracy: 0.1549 - val_aux_output_loss: 3.2091 - val_loss: 4.0011 - val_main_output_accuracy: 0.1740 - val_main_output_loss: 2.9733 - learning_rate: 9.0000e-05\n",
    "Epoch 4/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 310ms/step - aux_output_accuracy: 0.1991 - aux_output_loss: 2.9511 - loss: 3.4251 - main_output_accuracy: 0.2846 - main_output_loss: 2.4750\n",
    "Epoch 4: val_main_output_accuracy improved from 0.17402 to 0.31387, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 181s 324ms/step - aux_output_accuracy: 0.1992 - aux_output_loss: 2.9509 - loss: 3.4246 - main_output_accuracy: 0.2847 - main_output_loss: 2.4747 - val_aux_output_accuracy: 0.2562 - val_aux_output_loss: 2.8277 - val_loss: 3.3386 - val_main_output_accuracy: 0.3139 - val_main_output_loss: 2.4264 - learning_rate: 9.0000e-05\n",
    "Epoch 5/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 302ms/step - aux_output_accuracy: 0.3102 - aux_output_loss: 2.4493 - loss: 2.4838 - main_output_accuracy: 0.4936 - main_output_loss: 1.6855\n",
    "Epoch 5: val_main_output_accuracy improved from 0.31387 to 0.65020, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 317ms/step - aux_output_accuracy: 0.3102 - aux_output_loss: 2.4491 - loss: 2.4835 - main_output_accuracy: 0.4936 - main_output_loss: 1.6852 - val_aux_output_accuracy: 0.4850 - val_aux_output_loss: 2.0639 - val_loss: 2.0109 - val_main_output_accuracy: 0.6502 - val_main_output_loss: 1.3289 - learning_rate: 9.0000e-05\n",
    "Epoch 6/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.4142 - aux_output_loss: 2.0176 - loss: 1.8003 - main_output_accuracy: 0.6523 - main_output_loss: 1.1323\n",
    "Epoch 6: val_main_output_accuracy improved from 0.65020 to 0.72246, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 316ms/step - aux_output_accuracy: 0.4143 - aux_output_loss: 2.0175 - loss: 1.8001 - main_output_accuracy: 0.6523 - main_output_loss: 1.1322 - val_aux_output_accuracy: 0.5549 - val_aux_output_loss: 1.7931 - val_loss: 1.6799 - val_main_output_accuracy: 0.7225 - val_main_output_loss: 1.0799 - learning_rate: 8.1000e-05\n",
    "Epoch 7/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.4992 - aux_output_loss: 1.7137 - loss: 1.4302 - main_output_accuracy: 0.7336 - main_output_loss: 0.8543\n",
    "Epoch 7: val_main_output_accuracy improved from 0.72246 to 0.77324, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 316ms/step - aux_output_accuracy: 0.4992 - aux_output_loss: 1.7136 - loss: 1.4301 - main_output_accuracy: 0.7337 - main_output_loss: 0.8542 - val_aux_output_accuracy: 0.6031 - val_aux_output_loss: 1.5626 - val_loss: 1.3915 - val_main_output_accuracy: 0.7732 - val_main_output_loss: 0.8615 - learning_rate: 8.1000e-05\n",
    "Epoch 8/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 316ms/step - aux_output_accuracy: 0.5596 - aux_output_loss: 1.4721 - loss: 1.1790 - main_output_accuracy: 0.7897 - main_output_loss: 0.6763\n",
    "Epoch 8: val_main_output_accuracy did not improve from 0.77324\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 184s 330ms/step - aux_output_accuracy: 0.5597 - aux_output_loss: 1.4720 - loss: 1.1789 - main_output_accuracy: 0.7898 - main_output_loss: 0.6763 - val_aux_output_accuracy: 0.5766 - val_aux_output_loss: 1.5081 - val_loss: 1.3724 - val_main_output_accuracy: 0.7410 - val_main_output_loss: 0.8594 - learning_rate: 8.1000e-05\n",
    "Epoch 9/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 305ms/step - aux_output_accuracy: 0.6106 - aux_output_loss: 1.3002 - loss: 1.0322 - main_output_accuracy: 0.8166 - main_output_loss: 0.5818\n",
    "Epoch 9: val_main_output_accuracy improved from 0.77324 to 0.87090, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 320ms/step - aux_output_accuracy: 0.6107 - aux_output_loss: 1.3001 - loss: 1.0321 - main_output_accuracy: 0.8166 - main_output_loss: 0.5817 - val_aux_output_accuracy: 0.7367 - val_aux_output_loss: 1.0419 - val_loss: 0.8562 - val_main_output_accuracy: 0.8709 - val_main_output_loss: 0.4838 - learning_rate: 7.2900e-05\n",
    "Epoch 10/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 306ms/step - aux_output_accuracy: 0.6584 - aux_output_loss: 1.1325 - loss: 0.8582 - main_output_accuracy: 0.8561 - main_output_loss: 0.4587\n",
    "Epoch 10: val_main_output_accuracy did not improve from 0.87090\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 320ms/step - aux_output_accuracy: 0.6584 - aux_output_loss: 1.1325 - loss: 0.8582 - main_output_accuracy: 0.8561 - main_output_loss: 0.4587 - val_aux_output_accuracy: 0.5410 - val_aux_output_loss: 1.5699 - val_loss: 1.6272 - val_main_output_accuracy: 0.6687 - val_main_output_loss: 1.0970 - learning_rate: 7.2900e-05\n",
    "Epoch 11/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 305ms/step - aux_output_accuracy: 0.6831 - aux_output_loss: 1.0369 - loss: 0.7964 - main_output_accuracy: 0.8672 - main_output_loss: 0.4262\n",
    "Epoch 11: val_main_output_accuracy improved from 0.87090 to 0.88457, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 319ms/step - aux_output_accuracy: 0.6831 - aux_output_loss: 1.0369 - loss: 0.7964 - main_output_accuracy: 0.8672 - main_output_loss: 0.4262 - val_aux_output_accuracy: 0.7674 - val_aux_output_loss: 0.8542 - val_loss: 0.7156 - val_main_output_accuracy: 0.8846 - val_main_output_loss: 0.4006 - learning_rate: 7.2900e-05\n",
    "Epoch 12/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 303ms/step - aux_output_accuracy: 0.7090 - aux_output_loss: 0.9610 - loss: 0.7240 - main_output_accuracy: 0.8807 - main_output_loss: 0.3772\n",
    "Epoch 12: val_main_output_accuracy did not improve from 0.88457\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 318ms/step - aux_output_accuracy: 0.7090 - aux_output_loss: 0.9610 - loss: 0.7240 - main_output_accuracy: 0.8807 - main_output_loss: 0.3772 - val_aux_output_accuracy: 0.7398 - val_aux_output_loss: 0.9167 - val_loss: 0.7839 - val_main_output_accuracy: 0.8639 - val_main_output_loss: 0.4508 - learning_rate: 6.5610e-05\n",
    "Epoch 13/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 305ms/step - aux_output_accuracy: 0.7283 - aux_output_loss: 0.8742 - loss: 0.6495 - main_output_accuracy: 0.8957 - main_output_loss: 0.3293\n",
    "Epoch 13: val_main_output_accuracy improved from 0.88457 to 0.88906, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 320ms/step - aux_output_accuracy: 0.7283 - aux_output_loss: 0.8742 - loss: 0.6495 - main_output_accuracy: 0.8957 - main_output_loss: 0.3293 - val_aux_output_accuracy: 0.8256 - val_aux_output_loss: 0.6759 - val_loss: 0.6361 - val_main_output_accuracy: 0.8891 - val_main_output_loss: 0.3757 - learning_rate: 6.5610e-05\n",
    "Epoch 14/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 304ms/step - aux_output_accuracy: 0.7466 - aux_output_loss: 0.8160 - loss: 0.6125 - main_output_accuracy: 0.9017 - main_output_loss: 0.3103\n",
    "Epoch 14: val_main_output_accuracy improved from 0.88906 to 0.90898, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 319ms/step - aux_output_accuracy: 0.7466 - aux_output_loss: 0.8159 - loss: 0.6125 - main_output_accuracy: 0.9017 - main_output_loss: 0.3103 - val_aux_output_accuracy: 0.8211 - val_aux_output_loss: 0.6564 - val_loss: 0.5912 - val_main_output_accuracy: 0.9090 - val_main_output_loss: 0.3372 - learning_rate: 6.5610e-05\n",
    "Epoch 15/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.7658 - aux_output_loss: 0.7473 - loss: 0.5669 - main_output_accuracy: 0.9094 - main_output_loss: 0.2857\n",
    "Epoch 15: val_main_output_accuracy did not improve from 0.90898\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 315ms/step - aux_output_accuracy: 0.7658 - aux_output_loss: 0.7473 - loss: 0.5669 - main_output_accuracy: 0.9094 - main_output_loss: 0.2857 - val_aux_output_accuracy: 0.8051 - val_aux_output_loss: 0.6881 - val_loss: 0.5894 - val_main_output_accuracy: 0.9072 - val_main_output_loss: 0.3264 - learning_rate: 5.9049e-05\n",
    "Epoch 16/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 308ms/step - aux_output_accuracy: 0.7846 - aux_output_loss: 0.7015 - loss: 0.5105 - main_output_accuracy: 0.9199 - main_output_loss: 0.2435\n",
    "Epoch 16: val_main_output_accuracy did not improve from 0.90898\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 180s 322ms/step - aux_output_accuracy: 0.7846 - aux_output_loss: 0.7015 - loss: 0.5105 - main_output_accuracy: 0.9199 - main_output_loss: 0.2435 - val_aux_output_accuracy: 0.7682 - val_aux_output_loss: 0.8256 - val_loss: 0.7615 - val_main_output_accuracy: 0.8568 - val_main_output_loss: 0.4576 - learning_rate: 5.9049e-05\n",
    "Epoch 17/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 311ms/step - aux_output_accuracy: 0.7912 - aux_output_loss: 0.6694 - loss: 0.4961 - main_output_accuracy: 0.9225 - main_output_loss: 0.2391\n",
    "Epoch 17: val_main_output_accuracy improved from 0.90898 to 0.94121, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 182s 326ms/step - aux_output_accuracy: 0.7912 - aux_output_loss: 0.6694 - loss: 0.4960 - main_output_accuracy: 0.9225 - main_output_loss: 0.2391 - val_aux_output_accuracy: 0.8602 - val_aux_output_loss: 0.5082 - val_loss: 0.4158 - val_main_output_accuracy: 0.9412 - val_main_output_loss: 0.2075 - learning_rate: 5.9049e-05\n",
    "Epoch 18/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.8024 - aux_output_loss: 0.6293 - loss: 0.4732 - main_output_accuracy: 0.9263 - main_output_loss: 0.2287\n",
    "Epoch 18: val_main_output_accuracy did not improve from 0.94121\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 315ms/step - aux_output_accuracy: 0.8024 - aux_output_loss: 0.6293 - loss: 0.4732 - main_output_accuracy: 0.9263 - main_output_loss: 0.2287 - val_aux_output_accuracy: 0.8613 - val_aux_output_loss: 0.4880 - val_loss: 0.4099 - val_main_output_accuracy: 0.9408 - val_main_output_loss: 0.2081 - learning_rate: 5.3144e-05\n",
    "Epoch 19/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.8191 - aux_output_loss: 0.5693 - loss: 0.4299 - main_output_accuracy: 0.9338 - main_output_loss: 0.2037\n",
    "Epoch 19: val_main_output_accuracy improved from 0.94121 to 0.94134, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 316ms/step - aux_output_accuracy: 0.8191 - aux_output_loss: 0.5693 - loss: 0.4299 - main_output_accuracy: 0.9338 - main_output_loss: 0.2037 - val_aux_output_accuracy: 0.8738 - val_aux_output_loss: 0.4432 - val_loss: 0.3759 - val_main_output_accuracy: 0.9413 - val_main_output_loss: 0.1866 - learning_rate: 5.3144e-05\n",
    "Epoch 20/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 302ms/step - aux_output_accuracy: 0.8246 - aux_output_loss: 0.5361 - loss: 0.4036 - main_output_accuracy: 0.9381 - main_output_loss: 0.1878\n",
    "Epoch 20: val_main_output_accuracy did not improve from 0.94134\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 316ms/step - aux_output_accuracy: 0.8246 - aux_output_loss: 0.5361 - loss: 0.4036 - main_output_accuracy: 0.9381 - main_output_loss: 0.1878 - val_aux_output_accuracy: 0.7638 - val_aux_output_loss: 0.7732 - val_loss: 0.6829 - val_main_output_accuracy: 0.8782 - val_main_output_loss: 0.3941 - learning_rate: 5.3144e-05\n",
    "Epoch 21/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 304ms/step - aux_output_accuracy: 0.8285 - aux_output_loss: 0.5283 - loss: 0.3859 - main_output_accuracy: 0.9420 - main_output_loss: 0.1728\n",
    "Epoch 21: val_main_output_accuracy did not improve from 0.94134\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 318ms/step - aux_output_accuracy: 0.8285 - aux_output_loss: 0.5283 - loss: 0.3859 - main_output_accuracy: 0.9420 - main_output_loss: 0.1728 - val_aux_output_accuracy: 0.8360 - val_aux_output_loss: 0.5396 - val_loss: 0.4401 - val_main_output_accuracy: 0.9280 - val_main_output_loss: 0.2226 - learning_rate: 4.7830e-05\n",
    "Epoch 22/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 304ms/step - aux_output_accuracy: 0.8366 - aux_output_loss: 0.5087 - loss: 0.3744 - main_output_accuracy: 0.9440 - main_output_loss: 0.1675\n",
    "Epoch 22: val_main_output_accuracy improved from 0.94134 to 0.95056, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 318ms/step - aux_output_accuracy: 0.8366 - aux_output_loss: 0.5087 - loss: 0.3744 - main_output_accuracy: 0.9440 - main_output_loss: 0.1675 - val_aux_output_accuracy: 0.8872 - val_aux_output_loss: 0.3848 - val_loss: 0.3309 - val_main_output_accuracy: 0.9506 - val_main_output_loss: 0.1610 - learning_rate: 4.7830e-05\n",
    "Epoch 23/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 303ms/step - aux_output_accuracy: 0.8513 - aux_output_loss: 0.4655 - loss: 0.3443 - main_output_accuracy: 0.9524 - main_output_loss: 0.1507\n",
    "Epoch 23: val_main_output_accuracy did not improve from 0.95056\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 318ms/step - aux_output_accuracy: 0.8513 - aux_output_loss: 0.4655 - loss: 0.3443 - main_output_accuracy: 0.9524 - main_output_loss: 0.1507 - val_aux_output_accuracy: 0.8748 - val_aux_output_loss: 0.4322 - val_loss: 0.3730 - val_main_output_accuracy: 0.9423 - val_main_output_loss: 0.1886 - learning_rate: 4.7830e-05\n",
    "Epoch 24/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 305ms/step - aux_output_accuracy: 0.8583 - aux_output_loss: 0.4512 - loss: 0.3294 - main_output_accuracy: 0.9529 - main_output_loss: 0.1405\n",
    "Epoch 24: val_main_output_accuracy did not improve from 0.95056\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 319ms/step - aux_output_accuracy: 0.8583 - aux_output_loss: 0.4513 - loss: 0.3294 - main_output_accuracy: 0.9529 - main_output_loss: 0.1405 - val_aux_output_accuracy: 0.8603 - val_aux_output_loss: 0.4600 - val_loss: 0.4099 - val_main_output_accuracy: 0.9288 - val_main_output_loss: 0.2170 - learning_rate: 4.3047e-05\n",
    "Epoch 25/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.8613 - aux_output_loss: 0.4384 - loss: 0.3259 - main_output_accuracy: 0.9522 - main_output_loss: 0.1411\n",
    "Epoch 25: val_main_output_accuracy did not improve from 0.95056\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 175s 314ms/step - aux_output_accuracy: 0.8613 - aux_output_loss: 0.4384 - loss: 0.3259 - main_output_accuracy: 0.9522 - main_output_loss: 0.1411 - val_aux_output_accuracy: 0.8723 - val_aux_output_loss: 0.4438 - val_loss: 0.3848 - val_main_output_accuracy: 0.9386 - val_main_output_loss: 0.1973 - learning_rate: 4.3047e-05\n",
    "Epoch 26/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 304ms/step - aux_output_accuracy: 0.8655 - aux_output_loss: 0.4221 - loss: 0.3058 - main_output_accuracy: 0.9567 - main_output_loss: 0.1262\n",
    "Epoch 26: val_main_output_accuracy did not improve from 0.95056\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 318ms/step - aux_output_accuracy: 0.8655 - aux_output_loss: 0.4221 - loss: 0.3058 - main_output_accuracy: 0.9567 - main_output_loss: 0.1262 - val_aux_output_accuracy: 0.8880 - val_aux_output_loss: 0.3784 - val_loss: 0.3258 - val_main_output_accuracy: 0.9488 - val_main_output_loss: 0.1585 - learning_rate: 4.3047e-05\n",
    "Epoch 27/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.8744 - aux_output_loss: 0.3920 - loss: 0.2887 - main_output_accuracy: 0.9602 - main_output_loss: 0.1184\n",
    "Epoch 27: val_main_output_accuracy improved from 0.95056 to 0.95703, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 315ms/step - aux_output_accuracy: 0.8744 - aux_output_loss: 0.3920 - loss: 0.2887 - main_output_accuracy: 0.9602 - main_output_loss: 0.1184 - val_aux_output_accuracy: 0.8890 - val_aux_output_loss: 0.3684 - val_loss: 0.3091 - val_main_output_accuracy: 0.9570 - val_main_output_loss: 0.1456 - learning_rate: 3.8742e-05\n",
    "Epoch 28/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 306ms/step - aux_output_accuracy: 0.8753 - aux_output_loss: 0.3794 - loss: 0.2764 - main_output_accuracy: 0.9645 - main_output_loss: 0.1102\n",
    "Epoch 28: val_main_output_accuracy did not improve from 0.95703\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 320ms/step - aux_output_accuracy: 0.8753 - aux_output_loss: 0.3794 - loss: 0.2764 - main_output_accuracy: 0.9645 - main_output_loss: 0.1102 - val_aux_output_accuracy: 0.8984 - val_aux_output_loss: 0.3466 - val_loss: 0.3115 - val_main_output_accuracy: 0.9511 - val_main_output_loss: 0.1544 - learning_rate: 3.8742e-05\n",
    "Epoch 29/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 305ms/step - aux_output_accuracy: 0.8779 - aux_output_loss: 0.3723 - loss: 0.2790 - main_output_accuracy: 0.9633 - main_output_loss: 0.1153\n",
    "Epoch 29: val_main_output_accuracy did not improve from 0.95703\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 319ms/step - aux_output_accuracy: 0.8779 - aux_output_loss: 0.3723 - loss: 0.2790 - main_output_accuracy: 0.9633 - main_output_loss: 0.1153 - val_aux_output_accuracy: 0.8803 - val_aux_output_loss: 0.4019 - val_loss: 0.3808 - val_main_output_accuracy: 0.9339 - val_main_output_loss: 0.2071 - learning_rate: 3.8742e-05\n",
    "Epoch 30/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 307ms/step - aux_output_accuracy: 0.8812 - aux_output_loss: 0.3631 - loss: 0.2608 - main_output_accuracy: 0.9665 - main_output_loss: 0.1000\n",
    "Epoch 30: val_main_output_accuracy did not improve from 0.95703\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 179s 321ms/step - aux_output_accuracy: 0.8812 - aux_output_loss: 0.3631 - loss: 0.2608 - main_output_accuracy: 0.9665 - main_output_loss: 0.1000 - val_aux_output_accuracy: 0.8966 - val_aux_output_loss: 0.3476 - val_loss: 0.3220 - val_main_output_accuracy: 0.9506 - val_main_output_loss: 0.1653 - learning_rate: 3.4868e-05\n",
    "Epoch 31/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 300ms/step - aux_output_accuracy: 0.8911 - aux_output_loss: 0.3354 - loss: 0.2488 - main_output_accuracy: 0.9680 - main_output_loss: 0.0967\n",
    "Epoch 31: val_main_output_accuracy improved from 0.95703 to 0.95998, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 175s 314ms/step - aux_output_accuracy: 0.8911 - aux_output_loss: 0.3354 - loss: 0.2489 - main_output_accuracy: 0.9680 - main_output_loss: 0.0967 - val_aux_output_accuracy: 0.9066 - val_aux_output_loss: 0.3132 - val_loss: 0.2734 - val_main_output_accuracy: 0.9600 - val_main_output_loss: 0.1273 - learning_rate: 3.4868e-05\n",
    "Epoch 32/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.8857 - aux_output_loss: 0.3495 - loss: 0.2563 - main_output_accuracy: 0.9677 - main_output_loss: 0.1001\n",
    "Epoch 32: val_main_output_accuracy did not improve from 0.95998\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 175s 314ms/step - aux_output_accuracy: 0.8857 - aux_output_loss: 0.3495 - loss: 0.2563 - main_output_accuracy: 0.9677 - main_output_loss: 0.1001 - val_aux_output_accuracy: 0.9054 - val_aux_output_loss: 0.3228 - val_loss: 0.3091 - val_main_output_accuracy: 0.9508 - val_main_output_loss: 0.1603 - learning_rate: 3.4868e-05\n",
    "Epoch 33/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 298ms/step - aux_output_accuracy: 0.8894 - aux_output_loss: 0.3310 - loss: 0.2406 - main_output_accuracy: 0.9686 - main_output_loss: 0.0902\n",
    "Epoch 33: val_main_output_accuracy did not improve from 0.95998\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 174s 312ms/step - aux_output_accuracy: 0.8894 - aux_output_loss: 0.3310 - loss: 0.2406 - main_output_accuracy: 0.9686 - main_output_loss: 0.0902 - val_aux_output_accuracy: 0.8976 - val_aux_output_loss: 0.3392 - val_loss: 0.3170 - val_main_output_accuracy: 0.9464 - val_main_output_loss: 0.1632 - learning_rate: 3.1381e-05\n",
    "Epoch 34/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 297ms/step - aux_output_accuracy: 0.9010 - aux_output_loss: 0.3169 - loss: 0.2308 - main_output_accuracy: 0.9717 - main_output_loss: 0.0849\n",
    "Epoch 34: val_main_output_accuracy did not improve from 0.95998\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 173s 311ms/step - aux_output_accuracy: 0.9010 - aux_output_loss: 0.3169 - loss: 0.2308 - main_output_accuracy: 0.9717 - main_output_loss: 0.0849 - val_aux_output_accuracy: 0.8462 - val_aux_output_loss: 0.5009 - val_loss: 0.4781 - val_main_output_accuracy: 0.9147 - val_main_output_loss: 0.2754 - learning_rate: 3.1381e-05\n",
    "Epoch 35/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 305ms/step - aux_output_accuracy: 0.8940 - aux_output_loss: 0.3290 - loss: 0.2382 - main_output_accuracy: 0.9694 - main_output_loss: 0.0889\n",
    "Epoch 35: val_main_output_accuracy did not improve from 0.95998\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 319ms/step - aux_output_accuracy: 0.8940 - aux_output_loss: 0.3290 - loss: 0.2382 - main_output_accuracy: 0.9694 - main_output_loss: 0.0889 - val_aux_output_accuracy: 0.8980 - val_aux_output_loss: 0.3322 - val_loss: 0.3083 - val_main_output_accuracy: 0.9474 - val_main_output_loss: 0.1572 - learning_rate: 3.1381e-05\n",
    "Epoch 36/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 303ms/step - aux_output_accuracy: 0.9045 - aux_output_loss: 0.2883 - loss: 0.2199 - main_output_accuracy: 0.9693 - main_output_loss: 0.0830\n",
    "Epoch 36: val_main_output_accuracy did not improve from 0.95998\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 317ms/step - aux_output_accuracy: 0.9045 - aux_output_loss: 0.2883 - loss: 0.2199 - main_output_accuracy: 0.9693 - main_output_loss: 0.0830 - val_aux_output_accuracy: 0.8852 - val_aux_output_loss: 0.3780 - val_loss: 0.3385 - val_main_output_accuracy: 0.9474 - val_main_output_loss: 0.1741 - learning_rate: 2.8243e-05\n",
    "Epoch 37/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.9070 - aux_output_loss: 0.2782 - loss: 0.2131 - main_output_accuracy: 0.9724 - main_output_loss: 0.0795\n",
    "Epoch 37: val_main_output_accuracy improved from 0.95998 to 0.96606, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 316ms/step - aux_output_accuracy: 0.9070 - aux_output_loss: 0.2782 - loss: 0.2131 - main_output_accuracy: 0.9724 - main_output_loss: 0.0795 - val_aux_output_accuracy: 0.9160 - val_aux_output_loss: 0.2770 - val_loss: 0.2429 - val_main_output_accuracy: 0.9661 - val_main_output_loss: 0.1090 - learning_rate: 2.8243e-05\n",
    "Epoch 38/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 303ms/step - aux_output_accuracy: 0.9074 - aux_output_loss: 0.2865 - loss: 0.2128 - main_output_accuracy: 0.9744 - main_output_loss: 0.0769\n",
    "Epoch 38: val_main_output_accuracy did not improve from 0.96606\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 317ms/step - aux_output_accuracy: 0.9074 - aux_output_loss: 0.2865 - loss: 0.2128 - main_output_accuracy: 0.9744 - main_output_loss: 0.0769 - val_aux_output_accuracy: 0.8387 - val_aux_output_loss: 0.5195 - val_loss: 0.4440 - val_main_output_accuracy: 0.9258 - val_main_output_loss: 0.2369 - learning_rate: 2.8243e-05\n",
    "Epoch 39/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 301ms/step - aux_output_accuracy: 0.9118 - aux_output_loss: 0.2704 - loss: 0.2036 - main_output_accuracy: 0.9757 - main_output_loss: 0.0727\n",
    "Epoch 39: val_main_output_accuracy did not improve from 0.96606\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 315ms/step - aux_output_accuracy: 0.9118 - aux_output_loss: 0.2705 - loss: 0.2036 - main_output_accuracy: 0.9757 - main_output_loss: 0.0727 - val_aux_output_accuracy: 0.9062 - val_aux_output_loss: 0.3116 - val_loss: 0.2843 - val_main_output_accuracy: 0.9549 - val_main_output_loss: 0.1403 - learning_rate: 2.5419e-05\n",
    "Epoch 40/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 297ms/step - aux_output_accuracy: 0.9112 - aux_output_loss: 0.2609 - loss: 0.1933 - main_output_accuracy: 0.9765 - main_output_loss: 0.0655\n",
    "Epoch 40: val_main_output_accuracy did not improve from 0.96606\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 173s 310ms/step - aux_output_accuracy: 0.9111 - aux_output_loss: 0.2609 - loss: 0.1933 - main_output_accuracy: 0.9765 - main_output_loss: 0.0655 - val_aux_output_accuracy: 0.9066 - val_aux_output_loss: 0.3109 - val_loss: 0.2713 - val_main_output_accuracy: 0.9592 - val_main_output_loss: 0.1279 - learning_rate: 2.5419e-05\n",
    "Epoch 41/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 302ms/step - aux_output_accuracy: 0.9094 - aux_output_loss: 0.2682 - loss: 0.1983 - main_output_accuracy: 0.9765 - main_output_loss: 0.0685\n",
    "Epoch 41: val_main_output_accuracy improved from 0.96606 to 0.96724, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 316ms/step - aux_output_accuracy: 0.9094 - aux_output_loss: 0.2682 - loss: 0.1983 - main_output_accuracy: 0.9765 - main_output_loss: 0.0685 - val_aux_output_accuracy: 0.9307 - val_aux_output_loss: 0.2365 - val_loss: 0.2226 - val_main_output_accuracy: 0.9672 - val_main_output_loss: 0.1018 - learning_rate: 2.5419e-05\n",
    "Epoch 42/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 299ms/step - aux_output_accuracy: 0.9081 - aux_output_loss: 0.2643 - loss: 0.1982 - main_output_accuracy: 0.9763 - main_output_loss: 0.0697\n",
    "Epoch 42: val_main_output_accuracy did not improve from 0.96724\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 174s 313ms/step - aux_output_accuracy: 0.9081 - aux_output_loss: 0.2643 - loss: 0.1982 - main_output_accuracy: 0.9763 - main_output_loss: 0.0697 - val_aux_output_accuracy: 0.9254 - val_aux_output_loss: 0.2460 - val_loss: 0.2231 - val_main_output_accuracy: 0.9655 - val_main_output_loss: 0.0996 - learning_rate: 2.2877e-05\n",
    "Epoch 43/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 307ms/step - aux_output_accuracy: 0.9146 - aux_output_loss: 0.2508 - loss: 0.1817 - main_output_accuracy: 0.9813 - main_output_loss: 0.0574\n",
    "Epoch 43: val_main_output_accuracy improved from 0.96724 to 0.97096, saving model to checkpoints/best_model.weights.h5\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 179s 322ms/step - aux_output_accuracy: 0.9146 - aux_output_loss: 0.2508 - loss: 0.1817 - main_output_accuracy: 0.9813 - main_output_loss: 0.0574 - val_aux_output_accuracy: 0.9280 - val_aux_output_loss: 0.2446 - val_loss: 0.2187 - val_main_output_accuracy: 0.9710 - val_main_output_loss: 0.0958 - learning_rate: 2.2877e-05\n",
    "Epoch 44/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 304ms/step - aux_output_accuracy: 0.9155 - aux_output_loss: 0.2529 - loss: 0.1822 - main_output_accuracy: 0.9805 - main_output_loss: 0.0576\n",
    "Epoch 44: val_main_output_accuracy did not improve from 0.97096\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 318ms/step - aux_output_accuracy: 0.9155 - aux_output_loss: 0.2529 - loss: 0.1822 - main_output_accuracy: 0.9805 - main_output_loss: 0.0576 - val_aux_output_accuracy: 0.9217 - val_aux_output_loss: 0.2677 - val_loss: 0.2441 - val_main_output_accuracy: 0.9633 - val_main_output_loss: 0.1143 - learning_rate: 2.2877e-05\n",
    "Epoch 45/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 304ms/step - aux_output_accuracy: 0.9166 - aux_output_loss: 0.2457 - loss: 0.1850 - main_output_accuracy: 0.9783 - main_output_loss: 0.0627\n",
    "Epoch 45: val_main_output_accuracy did not improve from 0.97096\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 177s 318ms/step - aux_output_accuracy: 0.9166 - aux_output_loss: 0.2457 - loss: 0.1850 - main_output_accuracy: 0.9783 - main_output_loss: 0.0627 - val_aux_output_accuracy: 0.9149 - val_aux_output_loss: 0.2766 - val_loss: 0.2532 - val_main_output_accuracy: 0.9594 - val_main_output_loss: 0.1209 - learning_rate: 2.0589e-05\n",
    "Epoch 46/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 305ms/step - aux_output_accuracy: 0.9259 - aux_output_loss: 0.2305 - loss: 0.1788 - main_output_accuracy: 0.9805 - main_output_loss: 0.0611\n",
    "Epoch 46: val_main_output_accuracy did not improve from 0.97096\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 178s 319ms/step - aux_output_accuracy: 0.9259 - aux_output_loss: 0.2305 - loss: 0.1787 - main_output_accuracy: 0.9805 - main_output_loss: 0.0611 - val_aux_output_accuracy: 0.9286 - val_aux_output_loss: 0.2356 - val_loss: 0.2159 - val_main_output_accuracy: 0.9686 - val_main_output_loss: 0.0962 - learning_rate: 2.0589e-05\n",
    "Epoch 47/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 303ms/step - aux_output_accuracy: 0.9222 - aux_output_loss: 0.2295 - loss: 0.1732 - main_output_accuracy: 0.9808 - main_output_loss: 0.0561\n",
    "Epoch 47: val_main_output_accuracy did not improve from 0.97096\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 317ms/step - aux_output_accuracy: 0.9222 - aux_output_loss: 0.2295 - loss: 0.1732 - main_output_accuracy: 0.9808 - main_output_loss: 0.0561 - val_aux_output_accuracy: 0.9217 - val_aux_output_loss: 0.2567 - val_loss: 0.2285 - val_main_output_accuracy: 0.9672 - val_main_output_loss: 0.1028 - learning_rate: 2.0589e-05\n",
    "Epoch 48/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 302ms/step - aux_output_accuracy: 0.9209 - aux_output_loss: 0.2351 - loss: 0.1722 - main_output_accuracy: 0.9816 - main_output_loss: 0.0535\n",
    "Epoch 48: val_main_output_accuracy did not improve from 0.97096\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 176s 316ms/step - aux_output_accuracy: 0.9209 - aux_output_loss: 0.2351 - loss: 0.1722 - main_output_accuracy: 0.9816 - main_output_loss: 0.0535 - val_aux_output_accuracy: 0.9200 - val_aux_output_loss: 0.2564 - val_loss: 0.2352 - val_main_output_accuracy: 0.9629 - val_main_output_loss: 0.1094 - learning_rate: 1.8530e-05\n",
    "Epoch 49/50\n",
    "558/558 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 298ms/step - aux_output_accuracy: 0.9208 - aux_output_loss: 0.2368 - loss: 0.1752 - main_output_accuracy: 0.9816 - main_output_loss: 0.0561\n",
    "Epoch 49: val_main_output_accuracy did not improve from 0.97096\"\"\"\n",
    "\n",
    "\n",
    "train_acc, val_acc = [], []\n",
    "train_loss, val_loss = [], []   \n",
    "\n",
    "epoch_blocks = re.split(r\"Epoch \\d+/\\d+\", log_text)\n",
    "\n",
    "for block in epoch_blocks:\n",
    "    \n",
    "    train_match = re.search(r\"main_output_accuracy:\\s*([0-9.]+).*?main_output_loss:\\s*([0-9.]+)\", block, re.S)\n",
    "    \n",
    "    val_match = re.search(r\"val_main_output_accuracy:\\s*([0-9.]+).*?val_main_output_loss:\\s*([0-9.]+)\", block, re.S)\n",
    "\n",
    "    if train_match and val_match:\n",
    "        train_acc.append(float(train_match.group(1)))\n",
    "        train_loss.append(float(train_match.group(2)))\n",
    "        val_acc.append(float(val_match.group(1)))\n",
    "        val_loss.append(float(val_match.group(2)))\n",
    "\n",
    "epochs = range(1, len(train_acc)+1)\n",
    "print(f\"âœ… Clean data extracted for {len(train_acc)} epochs\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epochs, train_acc, 'b-', label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Val Accuracy')\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(epochs, train_loss, 'b-', label='Train Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Val Loss')\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8692816,
     "sourceId": 13671294,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
